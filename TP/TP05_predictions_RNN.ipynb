{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benj-admin/MAP583_X/blob/main/TP/TP05_predictions_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPfXTpAXB6MI"
      },
      "source": [
        "# Predicting Engine Failure with RNN\n",
        "\n",
        "In this practicals, the goal is to predict the failure of an engine. The training dataset is made of time series obtained from several sensors on the engine until failure. The test dataset is made of the start of these time series and a failure date.\n",
        "\n",
        "We will build a simple RNN taking as input the multi-dimensional time serie characterizing the engine and learn its parameters to predict the time of failure at each instant. At the start, the best prediction without any input data should be the average of the failure times in the dataset and as more and more data is fed in the RNN, it should give a better and better estimate.\n",
        "\n",
        "The dataset is provided by [NASA](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan), see also [Kaggle](https://www.kaggle.com/datasets/suriyachayatummagoon/cmapssdata?select=Damage+Propagation+Modeling.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "egcRZderB6MK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import gamma\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZZD9lpogB6MP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0f277d3b-c724-40c5-a57b-dbf3c0da660f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nCZo-JIUB6MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d81da4-46f0-4270-81fd-790957fdde92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: True \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMC18fSB6MW"
      },
      "source": [
        "## 1. Downloading the data\n",
        "\n",
        "This need to be done only once!\n",
        "\n",
        "You can find the data on the website of the [NASA](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan) or on [Kaggle](https://www.kaggle.com/datasets/suriyachayatummagoon/cmapssdata?select=Damage+Propagation+Modeling.pdf) or on my website:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6IUyhYERB6MX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29fa167e-6371-4cf1-936d-59f3ca8a1063"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ],
      "source": [
        "%mkdir data\n",
        "%cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xX0tNgXvB6Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f0fe840-3ca7-4b19-8a13-1c3e8a5313d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-22 21:45:11--  https://www.di.ens.fr/~lelarge/CMAPSSData.zip\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘CMAPSSData.zip’\n",
            "\n",
            "CMAPSSData.zip          [             <=>    ]  11.85M  1.91MB/s    in 20s     \n",
            "\n",
            "2025-10-22 21:45:33 (593 KB/s) - ‘CMAPSSData.zip’ saved [12425978]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://www.di.ens.fr/~lelarge/CMAPSSData.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4-R0S-6AB6Mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8833ee85-fcc8-4020-e5ce-bba38ed2e006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CMAPSSData.zip\n",
            "  inflating: Damage Propagation Modeling.pdf  \n",
            "  inflating: readme.txt              \n",
            "  inflating: RUL_FD001.txt           \n",
            "  inflating: RUL_FD002.txt           \n",
            "  inflating: RUL_FD003.txt           \n",
            "  inflating: RUL_FD004.txt           \n",
            "  inflating: test_FD001.txt          \n",
            "  inflating: test_FD002.txt          \n",
            "  inflating: test_FD003.txt          \n",
            "  inflating: test_FD004.txt          \n",
            "  inflating: train_FD001.txt         \n",
            "  inflating: train_FD002.txt         \n",
            "  inflating: train_FD003.txt         \n",
            "  inflating: train_FD004.txt         \n"
          ]
        }
      ],
      "source": [
        "!unzip CMAPSSData.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bDsmGAAKB6Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d645ad-87f8-4f67-a98d-ee6d9f9587aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw7cICW_B6Mi"
      },
      "source": [
        "## 2. Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LgNZ-5pzB6Mj"
      },
      "outputs": [],
      "source": [
        "def get_CMAPSSData(nb_file):\n",
        "    # get data from file and pre process it (normalization and convert to pandas)\n",
        "    dataset_train = pd.read_csv('./data/train_FD00{}.txt'.format(nb_file),\n",
        "                                sep=' ', header=None).drop([26, 27], axis=1)\n",
        "    dataset_test = pd.read_csv('./data/test_FD00{}.txt'.format(nb_file),\n",
        "                               sep=' ', header=None).drop([26, 27], axis=1)\n",
        "    test_truth = pd.read_csv('./data/RUL_FD00{}.txt'.format(nb_file),\n",
        "                             sep=' ', header=None).drop([1], axis=1)\n",
        "    col_names = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8',\n",
        "                 's9',\n",
        "                 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "    dataset_train.columns = col_names\n",
        "    dataset_test.columns = col_names\n",
        "    test_truth.columns = ['more']\n",
        "    test_truth['id'] = test_truth.index + 1\n",
        "    rul = pd.DataFrame(dataset_test.groupby('id')['cycle'].max()).reset_index()\n",
        "    rul.columns = ['id', 'max']\n",
        "    test_truth['rtf'] = test_truth['more'] + rul['max']\n",
        "    test_truth.drop('more', axis=1, inplace=True)\n",
        "    dataset_test = dataset_test.merge(test_truth, on=['id'], how='left')\n",
        "    dataset_test['ttf'] = dataset_test['rtf'] - dataset_test['cycle']\n",
        "    dataset_test.drop('rtf', axis=1, inplace=True)\n",
        "    dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max) - dataset_train['cycle']\n",
        "    features_col_name = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8',\n",
        "                         's9', 's10', 's11',\n",
        "                         's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "    target_col_name = 'ttf'\n",
        "    relevant_features_col_name = []\n",
        "    for col in features_col_name:\n",
        "        if not (len(dataset_train[col].unique()) == 1):\n",
        "            relevant_features_col_name.append(col)\n",
        "    sc = MinMaxScaler()\n",
        "    dataset_train[features_col_name] = sc.fit_transform(dataset_train[features_col_name])\n",
        "    dataset_test[features_col_name] = sc.transform(dataset_test[features_col_name])\n",
        "    return dataset_train, dataset_test, relevant_features_col_name, target_col_name\n",
        "\n",
        "\n",
        "def to_lists_of_tensors(dataset, features_col_name, target_col_name):\n",
        "    # take pandas df and convert it to list of tensors (for pytorch)\n",
        "    X, y = [], []\n",
        "    nb_sequences = max(dataset['id'])\n",
        "    for i in range(1, nb_sequences + 1):\n",
        "        df_zeros = dataset.loc[dataset['id'] == i]\n",
        "        df_one_x = df_zeros[features_col_name]\n",
        "        df_one_y = df_zeros[target_col_name]\n",
        "        X.append(torch.from_numpy(np.expand_dims(df_one_x.values, 1)).type(torch.FloatTensor))\n",
        "        y.append(torch.from_numpy(df_one_y.values).type(torch.FloatTensor))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def convert_train_and_test_to_appropriate_format(dataset_train, dataset_test, features_col_name, target_col_name):\n",
        "    # take 2 datasets (train and test and covert them to lists of tensors)\n",
        "    X_train, y_train = to_lists_of_tensors(dataset_train, features_col_name, target_col_name)\n",
        "    X_test, y_test = to_lists_of_tensors(dataset_test, features_col_name, target_col_name)\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4IJ-VFPXB6Ml"
      },
      "outputs": [],
      "source": [
        "%pycat ./data/readme.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "X-xRkXcQB6Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff459b9-d25a-4410-b971-433c965a2b76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2139691400.py:23: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max) - dataset_train['cycle']\n"
          ]
        }
      ],
      "source": [
        "dataset_train, dataset_test, features_col_name, target_col_name = get_CMAPSSData(1)\n",
        "X_train, y_train, X_test, y_test = convert_train_and_test_to_appropriate_format(dataset_train, dataset_test,\n",
        "                                                                                    features_col_name, target_col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uJoXsHBwB6Mq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "da5c0609-056f-453b-b2da-9df50fe2d048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
              "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
              "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
              "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
              "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
              "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
              "\n",
              "    s5  ...       s13       s14       s15  s16       s17  s18  s19       s20  \\\n",
              "0  0.0  ...  0.205882  0.199608  0.363986  0.0  0.333333  0.0  0.0  0.713178   \n",
              "1  0.0  ...  0.279412  0.162813  0.411312  0.0  0.333333  0.0  0.0  0.666667   \n",
              "2  0.0  ...  0.220588  0.171793  0.357445  0.0  0.166667  0.0  0.0  0.627907   \n",
              "3  0.0  ...  0.294118  0.174889  0.166603  0.0  0.333333  0.0  0.0  0.573643   \n",
              "4  0.0  ...  0.235294  0.174734  0.402078  0.0  0.416667  0.0  0.0  0.589147   \n",
              "\n",
              "        s21  ttf  \n",
              "0  0.724662  191  \n",
              "1  0.731014  190  \n",
              "2  0.621375  189  \n",
              "3  0.662386  188  \n",
              "4  0.704502  187  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-35d2abce-7620-4e97-88f7-3dcf9711632b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>...</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>ttf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.459770</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.183735</td>\n",
              "      <td>0.406802</td>\n",
              "      <td>0.309757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.199608</td>\n",
              "      <td>0.363986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713178</td>\n",
              "      <td>0.724662</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.609195</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.283133</td>\n",
              "      <td>0.453019</td>\n",
              "      <td>0.352633</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279412</td>\n",
              "      <td>0.162813</td>\n",
              "      <td>0.411312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.731014</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.252874</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>0.369523</td>\n",
              "      <td>0.370527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.220588</td>\n",
              "      <td>0.171793</td>\n",
              "      <td>0.357445</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.621375</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.540230</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>0.256159</td>\n",
              "      <td>0.331195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.174889</td>\n",
              "      <td>0.166603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573643</td>\n",
              "      <td>0.662386</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.390805</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.349398</td>\n",
              "      <td>0.257467</td>\n",
              "      <td>0.404625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.174734</td>\n",
              "      <td>0.402078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.589147</td>\n",
              "      <td>0.704502</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-35d2abce-7620-4e97-88f7-3dcf9711632b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-35d2abce-7620-4e97-88f7-3dcf9711632b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-35d2abce-7620-4e97-88f7-3dcf9711632b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9f8aaf61-7e4e-4de1-8f16-bfcfaa48f501\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9f8aaf61-7e4e-4de1-8f16-bfcfaa48f501')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9f8aaf61-7e4e-4de1-8f16-bfcfaa48f501 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_train"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "dataset_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs3X-PShB6Mt"
      },
      "source": [
        "Here I have done the minimal preprocessing of the data using the [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) of sklearn to scale each feature in (0,1).\n",
        "\n",
        "`X_train` is a list where each element is of shape (length_of_sequence,1,number_of_sensors) where the second dimension with value 1 corresponds to the batch size. As in the course, we will not proceed sequences by batches but one after the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "02WrnXXEB6Mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9987f0f9-5d7d-459b-abe5-c72439274ea5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([192, 1, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayDGRokNB6Mw"
      },
      "source": [
        "## 3. WTTE-RNN model\n",
        "\n",
        "Here, we follow an approach inspired from this [blog](https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/#wtte-rnn-produces-risk-embeddings).\n",
        "\n",
        "You first need to define a GRU (or LSTM) that will take as input a sequence of shape (length_of_sequence,1,number_of_sensors) and output a sequence of shape (length_of_sequence,2) obtained by passing the output of the GRU through a linear layer. As we want positive number, you will take the exponent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "61SxB3gYB6Mw"
      },
      "outputs": [],
      "source": [
        "class GRUnet(nn.Module):\n",
        "    def __init__(self, dim_input, num_layers, dim_hidden, dim_output=2):\n",
        "        super(GRUnet, self).__init__()\n",
        "\n",
        "        # --- Useful Constants ---\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = dim_hidden\n",
        "        self.dim_input = dim_input\n",
        "        self.dim_output = dim_output\n",
        "\n",
        "        # --- Manual GRU Cell Implementation ---\n",
        "\n",
        "        # 1. Layers for the CANDIDATE HIDDEN STATE (h_tilde)\n",
        "        self.fc_x2h = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2h = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 2. Layers for the RESET GATE (R)\n",
        "        self.fc_x2r = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2r = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 3. Layers for the UPDATE GATE (Z)\n",
        "        self.fc_x2z = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2z = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 4. Final Output Layer (or Prediction Layer)\n",
        "        self.fc_h2y = nn.Linear(dim_hidden,dim_output)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize the hidden state (h0).\n",
        "        h = x.new_zeros(1, self.hidden_dim)\n",
        "\n",
        "        # Loop over the time sequence\n",
        "        for t in range(x.size(0)):\n",
        "            # 1. Compute the Reset Gate (r)\n",
        "            r = torch.sigmoid(self.fc_x2r(x[t,:])+self.fc_h2r(h))\n",
        "\n",
        "            # 2. Compute the Candidate Hidden State\n",
        "            hb = torch.tanh(self.fc_x2h(x[t,:])+self.fc_h2h(r*h))\n",
        "\n",
        "            # 3. Compute the Update Gate (z)\n",
        "            z = torch.sigmoid(self.fc_x2z(x[t,:])+self.fc_h2z(h))\n",
        "\n",
        "            #4. Update the Hidden State (h(t))\n",
        "            h = z*hb + (1-z)*h\n",
        "\n",
        "        # --- Sortie Finale ---\n",
        "\n",
        "        return torch.nn.functional.softplus(self.fc_h2y(h))\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezsnVZjLB6Mz"
      },
      "source": [
        "Test your network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "NQAWWJ_kB6Mz"
      },
      "outputs": [],
      "source": [
        "model = GRUnet(dim_input=len(features_col_name), num_layers=3, dim_hidden=50)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "DLlNMl69B6M2"
      },
      "outputs": [],
      "source": [
        "output = model(X_train[0].to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "nJX0-hnjB6M4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb458bd1-1193-4fb4-a64f-4f8d8f5939ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhHb7vleB6M7"
      },
      "source": [
        "In order to learn the parameters of your RNN, you need to specify a loss and we will here follow a standard approach in reliability theory: we model the failure time as a [Weibull random variable](http://reliawiki.org/index.php/The_Weibull_Distribution)\n",
        "\n",
        "$$\n",
        "\\mathbb{P}(X>t) = \\exp(- \\left(\\frac{t}{\\eta}\\right)^{\\beta}),\n",
        "$$\n",
        "where $\\eta$ is the scale parameter and $\\beta$ is the shape parameter.\n",
        "\n",
        "Note that we have for the mean of a Weibull distribution:\n",
        "$$\n",
        "\\mathbb{E}[X] = \\eta \\Gamma(1+1/\\beta),\n",
        "$$\n",
        "where $\\Gamma$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function).\n",
        "\n",
        "In our case, we will interpret the 2 outputs of the RNN as estimates for the parameters $\\eta$ and $\\beta$. In order to design a loss, we compute the log-likelihood:\n",
        "\\begin{eqnarray*}\n",
        "\\log f(t) &=& \\log\\left( \\frac{\\beta}{\\eta}\\right) +(\\beta -1)\\log\\left(\\frac{t}{\\eta}\\right) -\\left(\\frac{t}\n",
        "{\\eta} \\right)^{\\beta}\\\\\n",
        "&=& \\log \\beta +\\beta \\log\\left(\\frac{t}{\\eta}\\right) -\\log t-\\left(\\frac{t}\n",
        "{\\eta} \\right)^{\\beta}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Define a loss function corresponding to the negative log-likelihood (add a small parameter $\\epsilon$ to $t$ in order not to compute $\\log 0$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mm7PPLLZB6M8"
      },
      "outputs": [],
      "source": [
        "class weibull_loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(weibull_loss, self).__init__()\n",
        "        self.epsilon = 1e-6\n",
        "\n",
        "    def forward(self, output, y):\n",
        "        eta, beta = output[0],output[1]\n",
        "        return -(torch.log(beta/eta) + (beta-1)*torch.log((y+self.epsilon)/eta) - ((y+self.epsilon)/eta)**(beta))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEqkoBsB6M-"
      },
      "source": [
        "Test your loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "QkyZMThqB6M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8af212a2-004e-487a-eda6-9acb138160a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([38.1064, 37.9863, 37.8660, 37.7454, 37.6246, 37.5035, 37.3822, 37.2606,\n",
              "        37.1388, 37.0167, 36.8944, 36.7718, 36.6489, 36.5258, 36.4024, 36.2788,\n",
              "        36.1548, 36.0306, 35.9062, 35.7814, 35.6564, 35.5311, 35.4055, 35.2796,\n",
              "        35.1534, 35.0270, 34.9002, 34.7732, 34.6458, 34.5182, 34.3902, 34.2620,\n",
              "        34.1334, 34.0045, 33.8753, 33.7458, 33.6160, 33.4858, 33.3554, 33.2246,\n",
              "        33.0934, 32.9619, 32.8301, 32.6980, 32.5655, 32.4326, 32.2994, 32.1659,\n",
              "        32.0320, 31.8977, 31.7631, 31.6281, 31.4927, 31.3570, 31.2208, 31.0843,\n",
              "        30.9474, 30.8101, 30.6724, 30.5343, 30.3958, 30.2569, 30.1176, 29.9779,\n",
              "        29.8377, 29.6971, 29.5561, 29.4146, 29.2727, 29.1304, 28.9876, 28.8443,\n",
              "        28.7006, 28.5564, 28.4118, 28.2666, 28.1210, 27.9749, 27.8283, 27.6812,\n",
              "        27.5336, 27.3854, 27.2367, 27.0876, 26.9378, 26.7875, 26.6367, 26.4853,\n",
              "        26.3334, 26.1809, 26.0278, 25.8741, 25.7198, 25.5649, 25.4093, 25.2532,\n",
              "        25.0964, 24.9390, 24.7809, 24.6222, 24.4628, 24.3027, 24.1419, 23.9804,\n",
              "        23.8182, 23.6553, 23.4916, 23.3272, 23.1620, 22.9960, 22.8292, 22.6616,\n",
              "        22.4932, 22.3240, 22.1539, 21.9830, 21.8112, 21.6384, 21.4648, 21.2902,\n",
              "        21.1147, 20.9382, 20.7607, 20.5822, 20.4026, 20.2220, 20.0403, 19.8576,\n",
              "        19.6736, 19.4886, 19.3023, 19.1149, 18.9262, 18.7363, 18.5450, 18.3525,\n",
              "        18.1585, 17.9632, 17.7664, 17.5682, 17.3684, 17.1671, 16.9642, 16.7596,\n",
              "        16.5534, 16.3453, 16.1355, 15.9238, 15.7102, 15.4946, 15.2769, 15.0571,\n",
              "        14.8351, 14.6108, 14.3842, 14.1550, 13.9233, 13.6889, 13.4517, 13.2116,\n",
              "        12.9685, 12.7222, 12.4725, 12.2193, 11.9624, 11.7016, 11.4366, 11.1673,\n",
              "        10.8934, 10.6146, 10.3304, 10.0407,  9.7449,  9.4425,  9.1331,  8.8160,\n",
              "         8.4905,  8.1557,  7.8107,  7.4541,  7.0847,  6.7004,  6.2992,  5.8779,\n",
              "         5.4327,  4.9580,  4.4459,  3.8838,  3.2501,  2.5010,  1.5143, -4.9818],\n",
              "       device='cuda:0', grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "loss_fn = weibull_loss()\n",
        "loss_fn(output.squeeze(),y_train[0].to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxdK_B1vB6NB"
      },
      "source": [
        "## 4. Training your model\n",
        "\n",
        "Code your taining and testing loops.\n",
        "\n",
        "You might want to use a scheduler like `torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose='True',threshold=0.001)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR1GA2KzB6NC"
      },
      "outputs": [],
      "source": [
        "def train_epoch(X_train, y_train, model, loss_fn, optimizer, device):\n",
        "    # train the model through the whole training dataset for one epoch\n",
        "    # return the corresponding loss on the epoch\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.\n",
        "\n",
        "    for inputs, targets in zip(X_train, y_train):\n",
        "        ## Load the inputs to device, and apply the pre-processing function\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    n_train = len(X_train)\n",
        "\n",
        "    return running_loss/n_train\n",
        "\n",
        "\n",
        "def test_epoch(X_test, y_test, model, loss_fn, device):\n",
        "    # evaluate the model through the whole testing dataset\n",
        "    # return the corresponding loss\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.\n",
        "\n",
        "    for inputs, targets in zip(X_train, y_train):\n",
        "        ## Load the inputs to device, and apply the pre-processing function\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    n_train = len(X_train)\n",
        "    return running_loss/n_train\n",
        "\n",
        "\n",
        "def fit(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, nb_epochs, device):\n",
        "    # fit the model by training it nb_epochs times\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose='True',threshold=0.001)\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        running_loss = train_epoch(X_train, y_train, model, loss_fn, optimizer, device)\n",
        "        test_loss = test_epoch(X_test, y_test, model, loss_fn, device)\n",
        "        print(f\"[TRAIN epoch{epoch}/{nb_epochs}] Train Loss: {train_loss:.5f} Test Loss: {test_loss:.5f}%\")\n",
        "        scheduler.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBixgIwBB6NE"
      },
      "outputs": [],
      "source": [
        "model = GRUnet(dim_input=len(features_col_name), num_layers=3, dim_hidden=50,dim_output=2)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwYUv3t5B6NG"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = weibull_loss()\n",
        "nb_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1J8VDkBTB6NI"
      },
      "outputs": [],
      "source": [
        "model, train_loss_t, test_loss_t = fit(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, nb_epochs,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL--b9nVB6NK"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_loss_t, test_loss_t):\n",
        "    nb_epochs = len(train_loss_t)\n",
        "    plt.plot(range(nb_epochs), train_loss_t, color='orange', label='Loss on the training set')\n",
        "    plt.plot(range(nb_epochs), test_loss_t, color='green', label='Loss on the testing set')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op0o9tx4B6NN"
      },
      "outputs": [],
      "source": [
        "plot_losses(train_loss_t, test_loss_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZ9dY4HB6NQ"
      },
      "source": [
        "## 5. Looking at your results\n",
        "\n",
        "To compute a baseline, I am computing the average of all failure times in the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVtYbGjkB6NQ"
      },
      "outputs": [],
      "source": [
        "max_val = np.zeros(len(y_train))\n",
        "for i,y in enumerate(y_train):\n",
        "    max_val[i] = y[0].item()\n",
        "baseline = np.mean(max_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYqaD1loB6NS"
      },
      "source": [
        "Here I am computing all the predictions made by my model on the test set and exporting these into `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_UttARgB6NS"
      },
      "outputs": [],
      "source": [
        "def compute_np(model,X_test, y_test,baseline=baseline,device=device,max_size=303):\n",
        "    n_test = len(X_test)\n",
        "    all_pred = np.empty((n_test,max_size,2))\n",
        "    all_y = np.empty((n_test,max_size))\n",
        "    base_pred = np.empty((n_test,max_size))\n",
        "    all_pred[:] = np.NaN\n",
        "    all_y[:] = np.NaN\n",
        "    base_pred[:] = np.NaN\n",
        "    list_npred = []\n",
        "    for k in range(n_test):\n",
        "        pred = model(X_test[k].to(device))\n",
        "        pred_np = pred.cpu().detach().numpy()\n",
        "        n_pred = pred_np.shape[0]\n",
        "        list_npred.append(n_pred)\n",
        "        all_pred[k,:n_pred,:] = pred_np\n",
        "        all_y[k,:n_pred] = y_test[k].numpy()\n",
        "        base_pred[k,:n_pred] = baseline - range(n_pred)\n",
        "    return all_pred, all_y, base_pred, list_npred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XWfOw9IB6NU"
      },
      "outputs": [],
      "source": [
        "all_pred, all_y, base_pred, list_npred = compute_np(model, X_test,y_test)\n",
        "pred_fail = all_pred[:,:,0]*gamma(1+1/all_pred[:,:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IdjZMAZB6NW"
      },
      "source": [
        "On the test set, we have only access to the start of the sequence and need to predict the failure time. For a given engine, you can compare the predictions made by the model, the baseline and the true value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdkmllHNB6NX"
      },
      "outputs": [],
      "source": [
        "k = 50\n",
        "plt.plot(pred_fail[k,:],label='predicted')\n",
        "plt.plot(all_y[k],label='true')\n",
        "plt.plot(base_pred[k],label='baseline')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeFL3HnQB6NZ"
      },
      "source": [
        "To get a measure of perfomance, we compute the RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKMLIflYB6Na"
      },
      "outputs": [],
      "source": [
        "def RMSE(pred_fail, all_y):\n",
        "    return np.sqrt((pred_fail-all_y)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAnsK8GxB6Nc"
      },
      "outputs": [],
      "source": [
        "res= RMSE(pred_fail,all_y)\n",
        "res_base = RMSE(base_pred,all_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrToJiZTB6Ne"
      },
      "source": [
        "The RMSE error is the distance between the esimation and the true line above. It is constant for the baseline and should decrease as we get more and more data with our model. Here is an example on the particular exmaple above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaCpHTDvB6Ne"
      },
      "outputs": [],
      "source": [
        "plt.plot(res[k])\n",
        "plt.plot(res_base[k])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sta7kgwB6Ng"
      },
      "source": [
        "Below, I am averaging the RMSE over the dataset keeping the time axis (note that each point is an average but not with the same number of samples).\n",
        "\n",
        "We see that the RMSE of the baseline is very bad for long sequences. This should be expected as these long sequences corresponds to healthy engines!\n",
        "\n",
        "To the contrary, our model get a decreasing RMSE as a function of the length of the input sequence.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/rmse.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7edZe3XAB6Nh"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.nanmean(res,0), label = 'RMSE')\n",
        "plt.plot(np.nanmean(res_base,0), label ='RMSE baseline')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MypycQKB6Nj"
      },
      "outputs": [],
      "source": [
        "np.nanmean(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7w8lxubB6Nk"
      },
      "outputs": [],
      "source": [
        "np.nanmean(res_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31ozUyp1B6Nm"
      },
      "outputs": [],
      "source": [
        "last_indices = list((~np.isnan(res)).sum(axis = 1) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvMJJAvtB6No"
      },
      "outputs": [],
      "source": [
        "np.mean([res[i,j] for i,j in enumerate(last_indices)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAF4CPtQB6Nq"
      },
      "outputs": [],
      "source": [
        "np.mean([res_base[i,j] for i,j in enumerate(last_indices)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFkoNORB6Ns"
      },
      "source": [
        "Above we see that we divided the RMSE by more than 2 compare to the baseline.\n",
        "\n",
        "Here we do a scatter plot of the predictions vs true values for the baseline method (closer to the diagonal in blue is better):\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/base_scatter.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65JosTRLB6Ns"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=[all_y[i,j] for i,j in enumerate(last_indices)],y=[base_pred[i,j] for i,j in enumerate(last_indices)],dropna=True,kind=\"kde\", n_levels=30, color=\"g\");\n",
        "plot.ax_joint.plot([0,150], [0,150], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ2KXoo8B6Nu"
      },
      "source": [
        "Now we do the same scatter plot with our model (colser to the diagonal in blue is better). We see a great improvement.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/model_scatter.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1-qdjrkB6Nu"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=[all_y[i,j] for i,j in enumerate(last_indices)],y=[pred_fail[i,j] for i,j in enumerate(last_indices)],dropna=True,kind=\"kde\", n_levels=30, color=\"g\");\n",
        "plot.ax_joint.plot([0,150], [0,150], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuzDlaPiB6Nw"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=all_y,y=pred_fail,dropna=True,kind=\"kde\", space=0, color=\"g\");\n",
        "plot.ax_joint.plot([0,200], [0,200], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}