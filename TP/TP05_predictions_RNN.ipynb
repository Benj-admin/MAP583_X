{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benj-admin/MAP583_X/blob/main/TP/TP05_predictions_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPfXTpAXB6MI"
      },
      "source": [
        "# Predicting Engine Failure with RNN\n",
        "\n",
        "In this practicals, the goal is to predict the failure of an engine. The training dataset is made of time series obtained from several sensors on the engine until failure. The test dataset is made of the start of these time series and a failure date.\n",
        "\n",
        "We will build a simple RNN taking as input the multi-dimensional time serie characterizing the engine and learn its parameters to predict the time of failure at each instant. At the start, the best prediction without any input data should be the average of the failure times in the dataset and as more and more data is fed in the RNN, it should give a better and better estimate.\n",
        "\n",
        "The dataset is provided by [NASA](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan), see also [Kaggle](https://www.kaggle.com/datasets/suriyachayatummagoon/cmapssdata?select=Damage+Propagation+Modeling.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "egcRZderB6MK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.special import gamma\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZZD9lpogB6MP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7214519a-eecf-46ce-b9c2-eeb3cd574c82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.8.0+cu126'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nCZo-JIUB6MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984d0d12-2dcf-480b-f8ce-fe2be671f282"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: False \n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMC18fSB6MW"
      },
      "source": [
        "## 1. Downloading the data\n",
        "\n",
        "This need to be done only once!\n",
        "\n",
        "You can find the data on the website of the [NASA](https://ti.arc.nasa.gov/tech/dash/groups/pcoe/prognostic-data-repository/#turbofan) or on [Kaggle](https://www.kaggle.com/datasets/suriyachayatummagoon/cmapssdata?select=Damage+Propagation+Modeling.pdf) or on my website:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6IUyhYERB6MX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ee65096-f029-4d73-c3ee-6075715da405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/data\n"
          ]
        }
      ],
      "source": [
        "%mkdir data\n",
        "%cd data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xX0tNgXvB6Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8f778a-88b0-40b0-fd04-346c679cb4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-23 10:30:34--  https://www.di.ens.fr/~lelarge/CMAPSSData.zip\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘CMAPSSData.zip’\n",
            "\n",
            "CMAPSSData.zip          [               <=>  ]  11.85M  1.28MB/s    in 18s     \n",
            "\n",
            "2025-10-23 10:30:53 (677 KB/s) - ‘CMAPSSData.zip’ saved [12425978]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://www.di.ens.fr/~lelarge/CMAPSSData.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4-R0S-6AB6Mc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bd3dfb4-f12d-4e1c-b670-8971bbff5006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  CMAPSSData.zip\n",
            "  inflating: Damage Propagation Modeling.pdf  \n",
            "  inflating: readme.txt              \n",
            "  inflating: RUL_FD001.txt           \n",
            "  inflating: RUL_FD002.txt           \n",
            "  inflating: RUL_FD003.txt           \n",
            "  inflating: RUL_FD004.txt           \n",
            "  inflating: test_FD001.txt          \n",
            "  inflating: test_FD002.txt          \n",
            "  inflating: test_FD003.txt          \n",
            "  inflating: test_FD004.txt          \n",
            "  inflating: train_FD001.txt         \n",
            "  inflating: train_FD002.txt         \n",
            "  inflating: train_FD003.txt         \n",
            "  inflating: train_FD004.txt         \n"
          ]
        }
      ],
      "source": [
        "!unzip CMAPSSData.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bDsmGAAKB6Mf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273f4e13-42e5-4e28-ef8d-63033906cc59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw7cICW_B6Mi"
      },
      "source": [
        "## 2. Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LgNZ-5pzB6Mj"
      },
      "outputs": [],
      "source": [
        "def get_CMAPSSData(nb_file):\n",
        "    # get data from file and pre process it (normalization and convert to pandas)\n",
        "    dataset_train = pd.read_csv('./data/train_FD00{}.txt'.format(nb_file),\n",
        "                                sep=' ', header=None).drop([26, 27], axis=1)\n",
        "    dataset_test = pd.read_csv('./data/test_FD00{}.txt'.format(nb_file),\n",
        "                               sep=' ', header=None).drop([26, 27], axis=1)\n",
        "    test_truth = pd.read_csv('./data/RUL_FD00{}.txt'.format(nb_file),\n",
        "                             sep=' ', header=None).drop([1], axis=1)\n",
        "    col_names = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8',\n",
        "                 's9',\n",
        "                 's10', 's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "    dataset_train.columns = col_names\n",
        "    dataset_test.columns = col_names\n",
        "    test_truth.columns = ['more']\n",
        "    test_truth['id'] = test_truth.index + 1\n",
        "    rul = pd.DataFrame(dataset_test.groupby('id')['cycle'].max()).reset_index()\n",
        "    rul.columns = ['id', 'max']\n",
        "    test_truth['rtf'] = test_truth['more'] + rul['max']\n",
        "    test_truth.drop('more', axis=1, inplace=True)\n",
        "    dataset_test = dataset_test.merge(test_truth, on=['id'], how='left')\n",
        "    dataset_test['ttf'] = dataset_test['rtf'] - dataset_test['cycle']\n",
        "    dataset_test.drop('rtf', axis=1, inplace=True)\n",
        "    dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max) - dataset_train['cycle']\n",
        "    features_col_name = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8',\n",
        "                         's9', 's10', 's11',\n",
        "                         's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21']\n",
        "    target_col_name = 'ttf'\n",
        "    relevant_features_col_name = []\n",
        "    for col in features_col_name:\n",
        "        if not (len(dataset_train[col].unique()) == 1):\n",
        "            relevant_features_col_name.append(col)\n",
        "    sc = MinMaxScaler()\n",
        "    dataset_train[features_col_name] = sc.fit_transform(dataset_train[features_col_name])\n",
        "    dataset_test[features_col_name] = sc.transform(dataset_test[features_col_name])\n",
        "    return dataset_train, dataset_test, relevant_features_col_name, target_col_name\n",
        "\n",
        "\n",
        "def to_lists_of_tensors(dataset, features_col_name, target_col_name):\n",
        "    # take pandas df and convert it to list of tensors (for pytorch)\n",
        "    X, y = [], []\n",
        "    nb_sequences = max(dataset['id'])\n",
        "    for i in range(1, nb_sequences + 1):\n",
        "        df_zeros = dataset.loc[dataset['id'] == i]\n",
        "        df_one_x = df_zeros[features_col_name]\n",
        "        df_one_y = df_zeros[target_col_name]\n",
        "        X.append(torch.from_numpy(np.expand_dims(df_one_x.values, 1)).type(torch.FloatTensor))\n",
        "        y.append(torch.from_numpy(df_one_y.values).type(torch.FloatTensor))\n",
        "    return X, y\n",
        "\n",
        "\n",
        "def convert_train_and_test_to_appropriate_format(dataset_train, dataset_test, features_col_name, target_col_name):\n",
        "    # take 2 datasets (train and test and covert them to lists of tensors)\n",
        "    X_train, y_train = to_lists_of_tensors(dataset_train, features_col_name, target_col_name)\n",
        "    X_test, y_test = to_lists_of_tensors(dataset_test, features_col_name, target_col_name)\n",
        "    return X_train, y_train, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4IJ-VFPXB6Ml"
      },
      "outputs": [],
      "source": [
        "%pycat ./data/readme.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "X-xRkXcQB6Mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd6d1b60-7252-4c8f-ec81-854440093ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2139691400.py:23: FutureWarning: The provided callable <built-in function max> is currently using SeriesGroupBy.max. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"max\" instead.\n",
            "  dataset_train['ttf'] = dataset_train.groupby(['id'])['cycle'].transform(max) - dataset_train['cycle']\n"
          ]
        }
      ],
      "source": [
        "dataset_train, dataset_test, features_col_name, target_col_name = get_CMAPSSData(1)\n",
        "X_train, y_train, X_test, y_test = convert_train_and_test_to_appropriate_format(dataset_train, dataset_test,\n",
        "                                                                                    features_col_name, target_col_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uJoXsHBwB6Mq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e017f1bd-cd7d-4828-e95b-bec89073f49a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
              "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
              "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
              "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
              "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
              "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
              "\n",
              "    s5  ...       s13       s14       s15  s16       s17  s18  s19       s20  \\\n",
              "0  0.0  ...  0.205882  0.199608  0.363986  0.0  0.333333  0.0  0.0  0.713178   \n",
              "1  0.0  ...  0.279412  0.162813  0.411312  0.0  0.333333  0.0  0.0  0.666667   \n",
              "2  0.0  ...  0.220588  0.171793  0.357445  0.0  0.166667  0.0  0.0  0.627907   \n",
              "3  0.0  ...  0.294118  0.174889  0.166603  0.0  0.333333  0.0  0.0  0.573643   \n",
              "4  0.0  ...  0.235294  0.174734  0.402078  0.0  0.416667  0.0  0.0  0.589147   \n",
              "\n",
              "        s21  ttf  \n",
              "0  0.724662  191  \n",
              "1  0.731014  190  \n",
              "2  0.621375  189  \n",
              "3  0.662386  188  \n",
              "4  0.704502  187  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d3abba6a-7398-407f-96cb-7537c19f59c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>cycle</th>\n",
              "      <th>setting1</th>\n",
              "      <th>setting2</th>\n",
              "      <th>setting3</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>...</th>\n",
              "      <th>s13</th>\n",
              "      <th>s14</th>\n",
              "      <th>s15</th>\n",
              "      <th>s16</th>\n",
              "      <th>s17</th>\n",
              "      <th>s18</th>\n",
              "      <th>s19</th>\n",
              "      <th>s20</th>\n",
              "      <th>s21</th>\n",
              "      <th>ttf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.459770</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.183735</td>\n",
              "      <td>0.406802</td>\n",
              "      <td>0.309757</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.205882</td>\n",
              "      <td>0.199608</td>\n",
              "      <td>0.363986</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.713178</td>\n",
              "      <td>0.724662</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0.609195</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.283133</td>\n",
              "      <td>0.453019</td>\n",
              "      <td>0.352633</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.279412</td>\n",
              "      <td>0.162813</td>\n",
              "      <td>0.411312</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.731014</td>\n",
              "      <td>190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0.252874</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>0.369523</td>\n",
              "      <td>0.370527</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.220588</td>\n",
              "      <td>0.171793</td>\n",
              "      <td>0.357445</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.621375</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0.540230</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343373</td>\n",
              "      <td>0.256159</td>\n",
              "      <td>0.331195</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.174889</td>\n",
              "      <td>0.166603</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.573643</td>\n",
              "      <td>0.662386</td>\n",
              "      <td>188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0.390805</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.349398</td>\n",
              "      <td>0.257467</td>\n",
              "      <td>0.404625</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.235294</td>\n",
              "      <td>0.174734</td>\n",
              "      <td>0.402078</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.589147</td>\n",
              "      <td>0.704502</td>\n",
              "      <td>187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3abba6a-7398-407f-96cb-7537c19f59c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d3abba6a-7398-407f-96cb-7537c19f59c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d3abba6a-7398-407f-96cb-7537c19f59c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1c70ac62-40b7-410f-8703-bb6d1211139b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1c70ac62-40b7-410f-8703-bb6d1211139b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1c70ac62-40b7-410f-8703-bb6d1211139b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_train"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "dataset_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs3X-PShB6Mt"
      },
      "source": [
        "Here I have done the minimal preprocessing of the data using the [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) of sklearn to scale each feature in (0,1).\n",
        "\n",
        "`X_train` is a list where each element is of shape (length_of_sequence,1,number_of_sensors) where the second dimension with value 1 corresponds to the batch size. As in the course, we will not proceed sequences by batches but one after the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "02WrnXXEB6Mt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acf9f04-d1b1-4298-ee56-89e65d048b29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([192, 1, 17])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "X_train[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayDGRokNB6Mw"
      },
      "source": [
        "## 3. WTTE-RNN model\n",
        "\n",
        "Here, we follow an approach inspired from this [blog](https://ragulpr.github.io/2016/12/22/WTTE-RNN-Hackless-churn-modeling/#wtte-rnn-produces-risk-embeddings).\n",
        "\n",
        "You first need to define a GRU (or LSTM) that will take as input a sequence of shape (length_of_sequence,1,number_of_sensors) and output a sequence of shape (length_of_sequence,2) obtained by passing the output of the GRU through a linear layer. As we want positive number, you will take the exponent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "61SxB3gYB6Mw"
      },
      "outputs": [],
      "source": [
        "class GRUnet(nn.Module):\n",
        "    def __init__(self, dim_input, num_layers, dim_hidden, dim_output=2):\n",
        "        super(GRUnet, self).__init__()\n",
        "\n",
        "        # --- Useful Constants ---\n",
        "\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_dim = dim_hidden\n",
        "        self.dim_input = dim_input\n",
        "        self.dim_output = dim_output\n",
        "\n",
        "        # --- Manual GRU Cell Implementation ---\n",
        "\n",
        "        # 1. Layers for the CANDIDATE HIDDEN STATE (h_tilde)\n",
        "        self.fc_x2h = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2h = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 2. Layers for the RESET GATE (R)\n",
        "        self.fc_x2r = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2r = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 3. Layers for the UPDATE GATE (Z)\n",
        "        self.fc_x2z = nn.Linear(dim_input, dim_hidden)\n",
        "        self.fc_h2z = nn.Linear(dim_hidden, dim_hidden, bias = False)\n",
        "\n",
        "        # 4. Final Output Layer (or Prediction Layer)\n",
        "        self.fc_h2y = nn.Linear(dim_hidden,dim_output)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Initialize the hidden state (h0), and the output_list.\n",
        "        h = x.new_zeros(1, self.hidden_dim)\n",
        "        out =  []\n",
        "\n",
        "        # Loop over the time sequence\n",
        "        for t in range(x.size(0)):\n",
        "            # 1. Compute the Reset Gate (r)\n",
        "            r = torch.sigmoid(self.fc_x2r(x[t,:])+self.fc_h2r(h))\n",
        "\n",
        "            # 2. Compute the Candidate Hidden State\n",
        "            hb = torch.tanh(self.fc_x2h(x[t,:])+self.fc_h2h(r*h))\n",
        "\n",
        "            # 3. Compute the Update Gate (z)\n",
        "            z = torch.sigmoid(self.fc_x2z(x[t,:])+self.fc_h2z(h))\n",
        "\n",
        "            #4. Update the Hidden State (h(t))\n",
        "            h = z*hb + (1-z)*h\n",
        "\n",
        "            #5. Store the output at this time in the list (y(t))\n",
        "            out.append(torch.exp(self.fc_h2y(h)))\n",
        "\n",
        "        # --- Sortie Finale ---\n",
        "        return torch.stack(out, dim=0)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezsnVZjLB6Mz"
      },
      "source": [
        "Test your network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NQAWWJ_kB6Mz"
      },
      "outputs": [],
      "source": [
        "model = GRUnet(dim_input=len(features_col_name), num_layers=3, dim_hidden=50)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "DLlNMl69B6M2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "aa08cdb1-1ab6-4d58-9290-28e122f7283b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0.9281, 0.8287]], grad_fn=<ExpBackward0>), tensor([[0.9540, 0.7901]], grad_fn=<ExpBackward0>), tensor([[1.0275, 0.7992]], grad_fn=<ExpBackward0>), tensor([[1.0281, 0.7942]], grad_fn=<ExpBackward0>), tensor([[1.0204, 0.7867]], grad_fn=<ExpBackward0>), tensor([[1.0527, 0.7999]], grad_fn=<ExpBackward0>), tensor([[1.0590, 0.7858]], grad_fn=<ExpBackward0>), tensor([[1.0697, 0.7959]], grad_fn=<ExpBackward0>), tensor([[1.0592, 0.7864]], grad_fn=<ExpBackward0>), tensor([[1.0546, 0.7896]], grad_fn=<ExpBackward0>), tensor([[1.0421, 0.7756]], grad_fn=<ExpBackward0>), tensor([[1.0577, 0.7841]], grad_fn=<ExpBackward0>), tensor([[1.0338, 0.7875]], grad_fn=<ExpBackward0>), tensor([[1.0436, 0.7821]], grad_fn=<ExpBackward0>), tensor([[1.0403, 0.7894]], grad_fn=<ExpBackward0>), tensor([[1.0554, 0.7845]], grad_fn=<ExpBackward0>), tensor([[1.0357, 0.7827]], grad_fn=<ExpBackward0>), tensor([[1.0477, 0.7878]], grad_fn=<ExpBackward0>), tensor([[1.0243, 0.7895]], grad_fn=<ExpBackward0>), tensor([[1.0640, 0.7877]], grad_fn=<ExpBackward0>), tensor([[1.0521, 0.7965]], grad_fn=<ExpBackward0>), tensor([[1.0507, 0.7813]], grad_fn=<ExpBackward0>), tensor([[1.0272, 0.7683]], grad_fn=<ExpBackward0>), tensor([[1.0454, 0.7752]], grad_fn=<ExpBackward0>), tensor([[1.0314, 0.7571]], grad_fn=<ExpBackward0>), tensor([[1.0147, 0.7659]], grad_fn=<ExpBackward0>), tensor([[1.0119, 0.7723]], grad_fn=<ExpBackward0>), tensor([[1.0551, 0.8019]], grad_fn=<ExpBackward0>), tensor([[1.0240, 0.7989]], grad_fn=<ExpBackward0>), tensor([[1.0809, 0.7964]], grad_fn=<ExpBackward0>), tensor([[1.0547, 0.8004]], grad_fn=<ExpBackward0>), tensor([[1.0645, 0.7892]], grad_fn=<ExpBackward0>), tensor([[1.0597, 0.7995]], grad_fn=<ExpBackward0>), tensor([[1.0181, 0.7951]], grad_fn=<ExpBackward0>), tensor([[1.0554, 0.7854]], grad_fn=<ExpBackward0>), tensor([[1.0463, 0.7820]], grad_fn=<ExpBackward0>), tensor([[1.0462, 0.7863]], grad_fn=<ExpBackward0>), tensor([[1.0626, 0.7895]], grad_fn=<ExpBackward0>), tensor([[1.0467, 0.7971]], grad_fn=<ExpBackward0>), tensor([[1.0384, 0.7919]], grad_fn=<ExpBackward0>), tensor([[1.0527, 0.7692]], grad_fn=<ExpBackward0>), tensor([[1.0284, 0.7768]], grad_fn=<ExpBackward0>), tensor([[1.0500, 0.7947]], grad_fn=<ExpBackward0>), tensor([[1.0647, 0.7839]], grad_fn=<ExpBackward0>), tensor([[1.0324, 0.7815]], grad_fn=<ExpBackward0>), tensor([[1.0227, 0.7814]], grad_fn=<ExpBackward0>), tensor([[1.0531, 0.7824]], grad_fn=<ExpBackward0>), tensor([[1.0364, 0.7864]], grad_fn=<ExpBackward0>), tensor([[1.0622, 0.7877]], grad_fn=<ExpBackward0>), tensor([[1.0588, 0.7886]], grad_fn=<ExpBackward0>), tensor([[1.0399, 0.7806]], grad_fn=<ExpBackward0>), tensor([[1.0175, 0.7721]], grad_fn=<ExpBackward0>), tensor([[1.0064, 0.7732]], grad_fn=<ExpBackward0>), tensor([[1.0235, 0.7924]], grad_fn=<ExpBackward0>), tensor([[1.0338, 0.7901]], grad_fn=<ExpBackward0>), tensor([[1.0297, 0.7866]], grad_fn=<ExpBackward0>), tensor([[1.0218, 0.7975]], grad_fn=<ExpBackward0>), tensor([[1.0484, 0.8100]], grad_fn=<ExpBackward0>), tensor([[1.0681, 0.7990]], grad_fn=<ExpBackward0>), tensor([[1.0356, 0.7935]], grad_fn=<ExpBackward0>), tensor([[1.0461, 0.8016]], grad_fn=<ExpBackward0>), tensor([[1.0403, 0.8138]], grad_fn=<ExpBackward0>), tensor([[1.0080, 0.7874]], grad_fn=<ExpBackward0>), tensor([[1.0271, 0.7882]], grad_fn=<ExpBackward0>), tensor([[1.0248, 0.7970]], grad_fn=<ExpBackward0>), tensor([[1.0336, 0.7978]], grad_fn=<ExpBackward0>), tensor([[1.0085, 0.7955]], grad_fn=<ExpBackward0>), tensor([[1.0160, 0.7991]], grad_fn=<ExpBackward0>), tensor([[1.0481, 0.8052]], grad_fn=<ExpBackward0>), tensor([[1.0393, 0.8007]], grad_fn=<ExpBackward0>), tensor([[1.0207, 0.7955]], grad_fn=<ExpBackward0>), tensor([[1.0299, 0.8046]], grad_fn=<ExpBackward0>), tensor([[1.0485, 0.7956]], grad_fn=<ExpBackward0>), tensor([[1.0423, 0.7700]], grad_fn=<ExpBackward0>), tensor([[0.9969, 0.7791]], grad_fn=<ExpBackward0>), tensor([[1.0534, 0.7801]], grad_fn=<ExpBackward0>), tensor([[1.0229, 0.7879]], grad_fn=<ExpBackward0>), tensor([[0.9963, 0.7943]], grad_fn=<ExpBackward0>), tensor([[0.9645, 0.7934]], grad_fn=<ExpBackward0>), tensor([[0.9797, 0.7925]], grad_fn=<ExpBackward0>), tensor([[0.9971, 0.7851]], grad_fn=<ExpBackward0>), tensor([[1.0033, 0.7977]], grad_fn=<ExpBackward0>), tensor([[1.0305, 0.7946]], grad_fn=<ExpBackward0>), tensor([[1.0152, 0.8000]], grad_fn=<ExpBackward0>), tensor([[1.0184, 0.8006]], grad_fn=<ExpBackward0>), tensor([[1.0102, 0.8039]], grad_fn=<ExpBackward0>), tensor([[1.0182, 0.8063]], grad_fn=<ExpBackward0>), tensor([[1.0098, 0.8025]], grad_fn=<ExpBackward0>), tensor([[0.9988, 0.7989]], grad_fn=<ExpBackward0>), tensor([[1.0184, 0.7784]], grad_fn=<ExpBackward0>), tensor([[0.9814, 0.7728]], grad_fn=<ExpBackward0>), tensor([[1.0070, 0.7643]], grad_fn=<ExpBackward0>), tensor([[1.0034, 0.7735]], grad_fn=<ExpBackward0>), tensor([[1.0034, 0.7840]], grad_fn=<ExpBackward0>), tensor([[0.9800, 0.7759]], grad_fn=<ExpBackward0>), tensor([[0.9940, 0.7911]], grad_fn=<ExpBackward0>), tensor([[0.9900, 0.7886]], grad_fn=<ExpBackward0>), tensor([[1.0109, 0.7947]], grad_fn=<ExpBackward0>), tensor([[0.9885, 0.8030]], grad_fn=<ExpBackward0>), tensor([[1.0077, 0.8040]], grad_fn=<ExpBackward0>), tensor([[1.0149, 0.7836]], grad_fn=<ExpBackward0>), tensor([[1.0081, 0.7744]], grad_fn=<ExpBackward0>), tensor([[1.0017, 0.7871]], grad_fn=<ExpBackward0>), tensor([[1.0174, 0.7931]], grad_fn=<ExpBackward0>), tensor([[0.9993, 0.7852]], grad_fn=<ExpBackward0>), tensor([[1.0179, 0.7801]], grad_fn=<ExpBackward0>), tensor([[0.9924, 0.7747]], grad_fn=<ExpBackward0>), tensor([[0.9938, 0.7708]], grad_fn=<ExpBackward0>), tensor([[0.9785, 0.7828]], grad_fn=<ExpBackward0>), tensor([[0.9898, 0.7905]], grad_fn=<ExpBackward0>), tensor([[0.9804, 0.8041]], grad_fn=<ExpBackward0>), tensor([[0.9692, 0.7913]], grad_fn=<ExpBackward0>), tensor([[0.9600, 0.7916]], grad_fn=<ExpBackward0>), tensor([[0.9695, 0.7976]], grad_fn=<ExpBackward0>), tensor([[1.0002, 0.8090]], grad_fn=<ExpBackward0>), tensor([[0.9892, 0.8030]], grad_fn=<ExpBackward0>), tensor([[1.0036, 0.8255]], grad_fn=<ExpBackward0>), tensor([[0.9799, 0.8234]], grad_fn=<ExpBackward0>), tensor([[0.9919, 0.8033]], grad_fn=<ExpBackward0>), tensor([[1.0088, 0.8083]], grad_fn=<ExpBackward0>), tensor([[1.0157, 0.8003]], grad_fn=<ExpBackward0>), tensor([[0.9821, 0.7892]], grad_fn=<ExpBackward0>), tensor([[0.9577, 0.7781]], grad_fn=<ExpBackward0>), tensor([[0.9275, 0.7815]], grad_fn=<ExpBackward0>), tensor([[0.9361, 0.7800]], grad_fn=<ExpBackward0>), tensor([[0.9536, 0.7966]], grad_fn=<ExpBackward0>), tensor([[0.9641, 0.7932]], grad_fn=<ExpBackward0>), tensor([[0.9591, 0.8023]], grad_fn=<ExpBackward0>), tensor([[0.9616, 0.8082]], grad_fn=<ExpBackward0>), tensor([[0.9598, 0.7945]], grad_fn=<ExpBackward0>), tensor([[0.9797, 0.7931]], grad_fn=<ExpBackward0>), tensor([[0.9525, 0.7786]], grad_fn=<ExpBackward0>), tensor([[0.9360, 0.7848]], grad_fn=<ExpBackward0>), tensor([[0.9347, 0.7903]], grad_fn=<ExpBackward0>), tensor([[0.9562, 0.8031]], grad_fn=<ExpBackward0>), tensor([[0.9370, 0.8024]], grad_fn=<ExpBackward0>), tensor([[0.9385, 0.8065]], grad_fn=<ExpBackward0>), tensor([[0.9712, 0.8021]], grad_fn=<ExpBackward0>), tensor([[0.9739, 0.7943]], grad_fn=<ExpBackward0>), tensor([[0.9670, 0.7744]], grad_fn=<ExpBackward0>), tensor([[0.9645, 0.8031]], grad_fn=<ExpBackward0>), tensor([[0.9552, 0.8041]], grad_fn=<ExpBackward0>), tensor([[0.9471, 0.8039]], grad_fn=<ExpBackward0>), tensor([[0.9235, 0.7994]], grad_fn=<ExpBackward0>), tensor([[0.8943, 0.8054]], grad_fn=<ExpBackward0>), tensor([[0.9118, 0.7954]], grad_fn=<ExpBackward0>), tensor([[0.9135, 0.7906]], grad_fn=<ExpBackward0>), tensor([[0.9243, 0.7906]], grad_fn=<ExpBackward0>), tensor([[0.9131, 0.7847]], grad_fn=<ExpBackward0>), tensor([[0.8906, 0.7961]], grad_fn=<ExpBackward0>), tensor([[0.8825, 0.8066]], grad_fn=<ExpBackward0>), tensor([[0.8792, 0.8061]], grad_fn=<ExpBackward0>), tensor([[0.8778, 0.8035]], grad_fn=<ExpBackward0>), tensor([[0.8895, 0.8039]], grad_fn=<ExpBackward0>), tensor([[0.9073, 0.8087]], grad_fn=<ExpBackward0>), tensor([[0.9135, 0.8101]], grad_fn=<ExpBackward0>), tensor([[0.9310, 0.8204]], grad_fn=<ExpBackward0>), tensor([[0.9328, 0.8182]], grad_fn=<ExpBackward0>), tensor([[0.9091, 0.8137]], grad_fn=<ExpBackward0>), tensor([[0.8621, 0.7918]], grad_fn=<ExpBackward0>), tensor([[0.8829, 0.7888]], grad_fn=<ExpBackward0>), tensor([[0.8887, 0.8028]], grad_fn=<ExpBackward0>), tensor([[0.8716, 0.8118]], grad_fn=<ExpBackward0>), tensor([[0.8509, 0.8095]], grad_fn=<ExpBackward0>), tensor([[0.8675, 0.8128]], grad_fn=<ExpBackward0>), tensor([[0.8533, 0.8179]], grad_fn=<ExpBackward0>), tensor([[0.8778, 0.8035]], grad_fn=<ExpBackward0>), tensor([[0.9036, 0.8140]], grad_fn=<ExpBackward0>), tensor([[0.8980, 0.8180]], grad_fn=<ExpBackward0>), tensor([[0.8581, 0.8238]], grad_fn=<ExpBackward0>), tensor([[0.8447, 0.8095]], grad_fn=<ExpBackward0>), tensor([[0.8464, 0.8109]], grad_fn=<ExpBackward0>), tensor([[0.8488, 0.8219]], grad_fn=<ExpBackward0>), tensor([[0.8495, 0.8366]], grad_fn=<ExpBackward0>), tensor([[0.8571, 0.8180]], grad_fn=<ExpBackward0>), tensor([[0.8568, 0.8162]], grad_fn=<ExpBackward0>), tensor([[0.8445, 0.8095]], grad_fn=<ExpBackward0>), tensor([[0.8535, 0.8058]], grad_fn=<ExpBackward0>), tensor([[0.8297, 0.8008]], grad_fn=<ExpBackward0>), tensor([[0.8370, 0.8243]], grad_fn=<ExpBackward0>), tensor([[0.8204, 0.8155]], grad_fn=<ExpBackward0>), tensor([[0.8184, 0.8042]], grad_fn=<ExpBackward0>), tensor([[0.8031, 0.8066]], grad_fn=<ExpBackward0>), tensor([[0.7999, 0.8144]], grad_fn=<ExpBackward0>), tensor([[0.8012, 0.8157]], grad_fn=<ExpBackward0>), tensor([[0.7685, 0.8164]], grad_fn=<ExpBackward0>), tensor([[0.7734, 0.8324]], grad_fn=<ExpBackward0>), tensor([[0.8014, 0.8517]], grad_fn=<ExpBackward0>), tensor([[0.7896, 0.8322]], grad_fn=<ExpBackward0>), tensor([[0.7658, 0.8351]], grad_fn=<ExpBackward0>), tensor([[0.7731, 0.8285]], grad_fn=<ExpBackward0>), tensor([[0.7618, 0.8329]], grad_fn=<ExpBackward0>)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "only one element tensors can be converted to Python scalars",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1398467127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-30358283.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# --- Sortie Finale ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "output = model(X_train[0].to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "nJX0-hnjB6M4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "b9265e7a-be40-4ef5-9ac4-5d4b6dccc083"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'shape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1384306181.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhHb7vleB6M7"
      },
      "source": [
        "In order to learn the parameters of your RNN, you need to specify a loss and we will here follow a standard approach in reliability theory: we model the failure time as a [Weibull random variable](http://reliawiki.org/index.php/The_Weibull_Distribution)\n",
        "\n",
        "$$\n",
        "\\mathbb{P}(X>t) = \\exp(- \\left(\\frac{t}{\\eta}\\right)^{\\beta}),\n",
        "$$\n",
        "where $\\eta$ is the scale parameter and $\\beta$ is the shape parameter.\n",
        "\n",
        "Note that we have for the mean of a Weibull distribution:\n",
        "$$\n",
        "\\mathbb{E}[X] = \\eta \\Gamma(1+1/\\beta),\n",
        "$$\n",
        "where $\\Gamma$ is the [Gamma function](https://en.wikipedia.org/wiki/Gamma_function).\n",
        "\n",
        "In our case, we will interpret the 2 outputs of the RNN as estimates for the parameters $\\eta$ and $\\beta$. In order to design a loss, we compute the log-likelihood:\n",
        "\\begin{eqnarray*}\n",
        "\\log f(t) &=& \\log\\left( \\frac{\\beta}{\\eta}\\right) +(\\beta -1)\\log\\left(\\frac{t}{\\eta}\\right) -\\left(\\frac{t}\n",
        "{\\eta} \\right)^{\\beta}\\\\\n",
        "&=& \\log \\beta +\\beta \\log\\left(\\frac{t}{\\eta}\\right) -\\log t-\\left(\\frac{t}\n",
        "{\\eta} \\right)^{\\beta}\n",
        "\\end{eqnarray*}\n",
        "\n",
        "Define a loss function corresponding to the negative log-likelihood (add a small parameter $\\epsilon$ to $t$ in order not to compute $\\log 0$)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "mm7PPLLZB6M8"
      },
      "outputs": [],
      "source": [
        "class weibull_loss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(weibull_loss, self).__init__()\n",
        "        self.epsilon = 1e-6\n",
        "\n",
        "    def forward(self, output, y):\n",
        "        eta, beta = output[0],output[1]\n",
        "        print(beta,eta)\n",
        "        print(\"y est :\",y)\n",
        "        print((y+self.epsilon)/eta)\n",
        "        return -(torch.log(beta/eta) + (beta-1)*torch.log((y+self.epsilon)/eta) - ((y+self.epsilon)/eta)**(beta))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJEqkoBsB6M-"
      },
      "source": [
        "Test your loss function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QkyZMThqB6M-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4841cf53-20e2-4d77-b240-15a65f04fdda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.6442, grad_fn=<SelectBackward0>) tensor(0.7825, grad_fn=<SelectBackward0>)\n",
            "y est : tensor([191., 190., 189., 188., 187., 186., 185., 184., 183., 182., 181., 180.,\n",
            "        179., 178., 177., 176., 175., 174., 173., 172., 171., 170., 169., 168.,\n",
            "        167., 166., 165., 164., 163., 162., 161., 160., 159., 158., 157., 156.,\n",
            "        155., 154., 153., 152., 151., 150., 149., 148., 147., 146., 145., 144.,\n",
            "        143., 142., 141., 140., 139., 138., 137., 136., 135., 134., 133., 132.,\n",
            "        131., 130., 129., 128., 127., 126., 125., 124., 123., 122., 121., 120.,\n",
            "        119., 118., 117., 116., 115., 114., 113., 112., 111., 110., 109., 108.,\n",
            "        107., 106., 105., 104., 103., 102., 101., 100.,  99.,  98.,  97.,  96.,\n",
            "         95.,  94.,  93.,  92.,  91.,  90.,  89.,  88.,  87.,  86.,  85.,  84.,\n",
            "         83.,  82.,  81.,  80.,  79.,  78.,  77.,  76.,  75.,  74.,  73.,  72.,\n",
            "         71.,  70.,  69.,  68.,  67.,  66.,  65.,  64.,  63.,  62.,  61.,  60.,\n",
            "         59.,  58.,  57.,  56.,  55.,  54.,  53.,  52.,  51.,  50.,  49.,  48.,\n",
            "         47.,  46.,  45.,  44.,  43.,  42.,  41.,  40.,  39.,  38.,  37.,  36.,\n",
            "         35.,  34.,  33.,  32.,  31.,  30.,  29.,  28.,  27.,  26.,  25.,  24.,\n",
            "         23.,  22.,  21.,  20.,  19.,  18.,  17.,  16.,  15.,  14.,  13.,  12.,\n",
            "         11.,  10.,   9.,   8.,   7.,   6.,   5.,   4.,   3.,   2.,   1.,   0.])\n",
            "tensor([2.4409e+02, 2.4281e+02, 2.4153e+02, 2.4025e+02, 2.3898e+02, 2.3770e+02,\n",
            "        2.3642e+02, 2.3514e+02, 2.3386e+02, 2.3259e+02, 2.3131e+02, 2.3003e+02,\n",
            "        2.2875e+02, 2.2747e+02, 2.2620e+02, 2.2492e+02, 2.2364e+02, 2.2236e+02,\n",
            "        2.2108e+02, 2.1981e+02, 2.1853e+02, 2.1725e+02, 2.1597e+02, 2.1469e+02,\n",
            "        2.1342e+02, 2.1214e+02, 2.1086e+02, 2.0958e+02, 2.0830e+02, 2.0703e+02,\n",
            "        2.0575e+02, 2.0447e+02, 2.0319e+02, 2.0191e+02, 2.0064e+02, 1.9936e+02,\n",
            "        1.9808e+02, 1.9680e+02, 1.9553e+02, 1.9425e+02, 1.9297e+02, 1.9169e+02,\n",
            "        1.9041e+02, 1.8914e+02, 1.8786e+02, 1.8658e+02, 1.8530e+02, 1.8402e+02,\n",
            "        1.8275e+02, 1.8147e+02, 1.8019e+02, 1.7891e+02, 1.7763e+02, 1.7636e+02,\n",
            "        1.7508e+02, 1.7380e+02, 1.7252e+02, 1.7124e+02, 1.6997e+02, 1.6869e+02,\n",
            "        1.6741e+02, 1.6613e+02, 1.6485e+02, 1.6358e+02, 1.6230e+02, 1.6102e+02,\n",
            "        1.5974e+02, 1.5846e+02, 1.5719e+02, 1.5591e+02, 1.5463e+02, 1.5335e+02,\n",
            "        1.5208e+02, 1.5080e+02, 1.4952e+02, 1.4824e+02, 1.4696e+02, 1.4569e+02,\n",
            "        1.4441e+02, 1.4313e+02, 1.4185e+02, 1.4057e+02, 1.3930e+02, 1.3802e+02,\n",
            "        1.3674e+02, 1.3546e+02, 1.3418e+02, 1.3291e+02, 1.3163e+02, 1.3035e+02,\n",
            "        1.2907e+02, 1.2779e+02, 1.2652e+02, 1.2524e+02, 1.2396e+02, 1.2268e+02,\n",
            "        1.2140e+02, 1.2013e+02, 1.1885e+02, 1.1757e+02, 1.1629e+02, 1.1501e+02,\n",
            "        1.1374e+02, 1.1246e+02, 1.1118e+02, 1.0990e+02, 1.0863e+02, 1.0735e+02,\n",
            "        1.0607e+02, 1.0479e+02, 1.0351e+02, 1.0224e+02, 1.0096e+02, 9.9679e+01,\n",
            "        9.8402e+01, 9.7124e+01, 9.5846e+01, 9.4568e+01, 9.3290e+01, 9.2012e+01,\n",
            "        9.0734e+01, 8.9456e+01, 8.8178e+01, 8.6900e+01, 8.5622e+01, 8.4344e+01,\n",
            "        8.3066e+01, 8.1788e+01, 8.0510e+01, 7.9232e+01, 7.7954e+01, 7.6677e+01,\n",
            "        7.5399e+01, 7.4121e+01, 7.2843e+01, 7.1565e+01, 7.0287e+01, 6.9009e+01,\n",
            "        6.7731e+01, 6.6453e+01, 6.5175e+01, 6.3897e+01, 6.2619e+01, 6.1341e+01,\n",
            "        6.0063e+01, 5.8785e+01, 5.7507e+01, 5.6229e+01, 5.4951e+01, 5.3674e+01,\n",
            "        5.2396e+01, 5.1118e+01, 4.9840e+01, 4.8562e+01, 4.7284e+01, 4.6006e+01,\n",
            "        4.4728e+01, 4.3450e+01, 4.2172e+01, 4.0894e+01, 3.9616e+01, 3.8338e+01,\n",
            "        3.7060e+01, 3.5782e+01, 3.4504e+01, 3.3226e+01, 3.1949e+01, 3.0671e+01,\n",
            "        2.9393e+01, 2.8115e+01, 2.6837e+01, 2.5559e+01, 2.4281e+01, 2.3003e+01,\n",
            "        2.1725e+01, 2.0447e+01, 1.9169e+01, 1.7891e+01, 1.6613e+01, 1.5335e+01,\n",
            "        1.4057e+01, 1.2779e+01, 1.1501e+01, 1.0224e+01, 8.9456e+00, 7.6677e+00,\n",
            "        6.3897e+00, 5.1118e+00, 3.8338e+00, 2.5559e+00, 1.2779e+00, 1.2779e-06],\n",
            "       grad_fn=<DivBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([36.6679, 36.5495, 36.4309, 36.3120, 36.1930, 36.0736, 35.9541, 35.8343,\n",
              "        35.7143, 35.5940, 35.4735, 35.3527, 35.2317, 35.1105, 34.9890, 34.8672,\n",
              "        34.7452, 34.6230, 34.5005, 34.3777, 34.2546, 34.1313, 34.0078, 33.8839,\n",
              "        33.7598, 33.6354, 33.5108, 33.3858, 33.2606, 33.1351, 33.0093, 32.8833,\n",
              "        32.7569, 32.6303, 32.5033, 32.3761, 32.2485, 32.1207, 31.9925, 31.8641,\n",
              "        31.7353, 31.6062, 31.4768, 31.3471, 31.2171, 31.0867, 30.9560, 30.8250,\n",
              "        30.6936, 30.5619, 30.4298, 30.2975, 30.1647, 30.0316, 29.8982, 29.7644,\n",
              "        29.6302, 29.4957, 29.3608, 29.2255, 29.0898, 28.9538, 28.8173, 28.6805,\n",
              "        28.5433, 28.4057, 28.2677, 28.1293, 27.9904, 27.8512, 27.7115, 27.5714,\n",
              "        27.4309, 27.2899, 27.1485, 27.0066, 26.8643, 26.7215, 26.5783, 26.4346,\n",
              "        26.2904, 26.1457, 26.0006, 25.8549, 25.7088, 25.5621, 25.4150, 25.2673,\n",
              "        25.1191, 24.9703, 24.8210, 24.6712, 24.5208, 24.3698, 24.2183, 24.0662,\n",
              "        23.9135, 23.7602, 23.6063, 23.4517, 23.2966, 23.1408, 22.9843, 22.8273,\n",
              "        22.6695, 22.5111, 22.3519, 22.1921, 22.0316, 21.8703, 21.7083, 21.5456,\n",
              "        21.3821, 21.2178, 21.0528, 20.8869, 20.7202, 20.5527, 20.3843, 20.2151,\n",
              "        20.0450, 19.8739, 19.7020, 19.5291, 19.3553, 19.1805, 19.0047, 18.8279,\n",
              "        18.6500, 18.4711, 18.2911, 18.1099, 17.9276, 17.7442, 17.5596, 17.3737,\n",
              "        17.1866, 16.9981, 16.8084, 16.6173, 16.4248, 16.2309, 16.0354, 15.8385,\n",
              "        15.6400, 15.4399, 15.2381, 15.0346, 14.8294, 14.6223, 14.4133, 14.2024,\n",
              "        13.9894, 13.7743, 13.5570, 13.3375, 13.1156, 12.8913, 12.6644, 12.4348,\n",
              "        12.2025, 11.9672, 11.7288, 11.4872, 11.2423, 10.9938, 10.7415, 10.4852,\n",
              "        10.2247,  9.9597,  9.6899,  9.4150,  9.1345,  8.8481,  8.5552,  8.2554,\n",
              "         7.9479,  7.6320,  7.3067,  6.9711,  6.6237,  6.2629,  5.8867,  5.4924,\n",
              "         5.0764,  4.6337,  4.1572,  3.6356,  3.0493,  2.3588,  1.4529, -4.6337],\n",
              "       grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "loss_fn = weibull_loss()\n",
        "loss_fn(output.squeeze(),y_train[0].to(device))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxdK_B1vB6NB"
      },
      "source": [
        "## 4. Training your model\n",
        "\n",
        "Code your taining and testing loops.\n",
        "\n",
        "You might want to use a scheduler like `torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=1, verbose='True',threshold=0.001)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "nR1GA2KzB6NC"
      },
      "outputs": [],
      "source": [
        "def train_epoch(X_train, y_train, model, loss_fn, optimizer, device):\n",
        "    # train the model through the whole training dataset for one epoch\n",
        "    # return the corresponding loss on the epoch\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0.\n",
        "\n",
        "    n_samples = len(X_train)\n",
        "    indices = np.arange(n_samples)\n",
        "    np.random.shuffle(indices)\n",
        "    X_train = [X_train[i] for i in indices]\n",
        "    y_train = [y_train[i] for i in indices]\n",
        "\n",
        "    for inputs, targets in zip(X_train, y_train):\n",
        "        ## Load the inputs to device, and apply the pre-processing function\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs.squeeze(), targets)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    n_train = len(X_train)\n",
        "\n",
        "    return running_loss/n_train\n",
        "\n",
        "\n",
        "def test_epoch(X_test, y_test, model, loss_fn, device):\n",
        "    # evaluate the model through the whole testing dataset\n",
        "    # return the corresponding loss\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.\n",
        "\n",
        "    for inputs, targets in zip(X_test, y_test):\n",
        "        ## Load the inputs to device, and apply the pre-processing function\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs.squeeze(), targets)\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    n_test = len(X_test)\n",
        "    return running_loss/n_test\n",
        "\n",
        "\n",
        "def fit(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, nb_epochs, device):\n",
        "    # fit the model by training it nb_epochs times\n",
        "    train_loss_t, test_loss_t = [], []\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=1,threshold=0.001)\n",
        "\n",
        "    for epoch in range(nb_epochs):\n",
        "        train_loss = train_epoch(X_train, y_train, model, loss_fn, optimizer, device)\n",
        "        train_loss_t.append(train_loss)\n",
        "        test_loss = test_epoch(X_test, y_test, model, loss_fn, device)\n",
        "        test_loss_t.append(test_loss)\n",
        "        print(f\"[TRAIN epoch{epoch}/{nb_epochs}] Train Loss: {train_loss:.5f} Test Loss: {test_loss:.5f}%\")\n",
        "        scheduler.step(test_loss)\n",
        "    return model, train_loss_t, test_loss_t\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "lBixgIwBB6NE"
      },
      "outputs": [],
      "source": [
        "model = GRUnet(dim_input=len(features_col_name), num_layers=3, dim_hidden=50,dim_output=2)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "lwYUv3t5B6NG"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = weibull_loss()\n",
        "nb_epochs = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "1J8VDkBTB6NI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 772
        },
        "outputId": "00bcf708-12fb-4e2c-90a7-5181374086cd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "grad can be implicitly created only for scalar outputs",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1501513435.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1246957115.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, nb_epochs, device)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mtrain_loss_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1246957115.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(X_train, y_train, model, loss_fn, optimizer, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    645\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m             )\n\u001b[0;32m--> 647\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mout_numel_is_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_numel_is_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                     raise RuntimeError(\n\u001b[0m\u001b[1;32m    200\u001b[0m                         \u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     )\n",
            "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
          ]
        }
      ],
      "source": [
        "model, train_loss_t, test_loss_t = fit(model, X_train, y_train, X_test, y_test, optimizer, loss_fn, nb_epochs,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HL--b9nVB6NK"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_loss_t, test_loss_t):\n",
        "    nb_epochs = len(train_loss_t)\n",
        "    plt.plot(range(nb_epochs), train_loss_t, color='orange', label='Loss on the training set')\n",
        "    plt.plot(range(nb_epochs), test_loss_t, color='green', label='Loss on the testing set')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "op0o9tx4B6NN"
      },
      "outputs": [],
      "source": [
        "plot_losses(train_loss_t, test_loss_t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFZ9dY4HB6NQ"
      },
      "source": [
        "## 5. Looking at your results\n",
        "\n",
        "To compute a baseline, I am computing the average of all failure times in the train dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVtYbGjkB6NQ"
      },
      "outputs": [],
      "source": [
        "max_val = np.zeros(len(y_train))\n",
        "for i,y in enumerate(y_train):\n",
        "    max_val[i] = y[0].item()\n",
        "baseline = np.mean(max_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYqaD1loB6NS"
      },
      "source": [
        "Here I am computing all the predictions made by my model on the test set and exporting these into `numpy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_UttARgB6NS"
      },
      "outputs": [],
      "source": [
        "def compute_np(model,X_test, y_test,baseline=baseline,device=device,max_size=303):\n",
        "    n_test = len(X_test)\n",
        "    all_pred = np.empty((n_test,max_size,2))\n",
        "    all_y = np.empty((n_test,max_size))\n",
        "    base_pred = np.empty((n_test,max_size))\n",
        "    all_pred[:] = np.NaN\n",
        "    all_y[:] = np.NaN\n",
        "    base_pred[:] = np.NaN\n",
        "    list_npred = []\n",
        "    for k in range(n_test):\n",
        "        pred = model(X_test[k].to(device))\n",
        "        pred_np = pred.cpu().detach().numpy()\n",
        "        n_pred = pred_np.shape[0]\n",
        "        list_npred.append(n_pred)\n",
        "        all_pred[k,:n_pred,:] = pred_np\n",
        "        all_y[k,:n_pred] = y_test[k].numpy()\n",
        "        base_pred[k,:n_pred] = baseline - range(n_pred)\n",
        "    return all_pred, all_y, base_pred, list_npred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XWfOw9IB6NU"
      },
      "outputs": [],
      "source": [
        "all_pred, all_y, base_pred, list_npred = compute_np(model, X_test,y_test)\n",
        "pred_fail = all_pred[:,:,0]*gamma(1+1/all_pred[:,:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IdjZMAZB6NW"
      },
      "source": [
        "On the test set, we have only access to the start of the sequence and need to predict the failure time. For a given engine, you can compare the predictions made by the model, the baseline and the true value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdkmllHNB6NX"
      },
      "outputs": [],
      "source": [
        "k = 50\n",
        "plt.plot(pred_fail[k,:],label='predicted')\n",
        "plt.plot(all_y[k],label='true')\n",
        "plt.plot(base_pred[k],label='baseline')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeFL3HnQB6NZ"
      },
      "source": [
        "To get a measure of perfomance, we compute the RMSE:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKMLIflYB6Na"
      },
      "outputs": [],
      "source": [
        "def RMSE(pred_fail, all_y):\n",
        "    return np.sqrt((pred_fail-all_y)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAnsK8GxB6Nc"
      },
      "outputs": [],
      "source": [
        "res= RMSE(pred_fail,all_y)\n",
        "res_base = RMSE(base_pred,all_y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrToJiZTB6Ne"
      },
      "source": [
        "The RMSE error is the distance between the esimation and the true line above. It is constant for the baseline and should decrease as we get more and more data with our model. Here is an example on the particular exmaple above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaCpHTDvB6Ne"
      },
      "outputs": [],
      "source": [
        "plt.plot(res[k])\n",
        "plt.plot(res_base[k])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sta7kgwB6Ng"
      },
      "source": [
        "Below, I am averaging the RMSE over the dataset keeping the time axis (note that each point is an average but not with the same number of samples).\n",
        "\n",
        "We see that the RMSE of the baseline is very bad for long sequences. This should be expected as these long sequences corresponds to healthy engines!\n",
        "\n",
        "To the contrary, our model get a decreasing RMSE as a function of the length of the input sequence.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/rmse.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7edZe3XAB6Nh"
      },
      "outputs": [],
      "source": [
        "plt.plot(np.nanmean(res,0), label = 'RMSE')\n",
        "plt.plot(np.nanmean(res_base,0), label ='RMSE baseline')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MypycQKB6Nj"
      },
      "outputs": [],
      "source": [
        "np.nanmean(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7w8lxubB6Nk"
      },
      "outputs": [],
      "source": [
        "np.nanmean(res_base)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31ozUyp1B6Nm"
      },
      "outputs": [],
      "source": [
        "last_indices = list((~np.isnan(res)).sum(axis = 1) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvMJJAvtB6No"
      },
      "outputs": [],
      "source": [
        "np.mean([res[i,j] for i,j in enumerate(last_indices)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAF4CPtQB6Nq"
      },
      "outputs": [],
      "source": [
        "np.mean([res_base[i,j] for i,j in enumerate(last_indices)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoFkoNORB6Ns"
      },
      "source": [
        "Above we see that we divided the RMSE by more than 2 compare to the baseline.\n",
        "\n",
        "Here we do a scatter plot of the predictions vs true values for the baseline method (closer to the diagonal in blue is better):\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/base_scatter.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65JosTRLB6Ns"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=[all_y[i,j] for i,j in enumerate(last_indices)],y=[base_pred[i,j] for i,j in enumerate(last_indices)],dropna=True,kind=\"kde\", n_levels=30, color=\"g\");\n",
        "plot.ax_joint.plot([0,150], [0,150], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZ2KXoo8B6Nu"
      },
      "source": [
        "Now we do the same scatter plot with our model (colser to the diagonal in blue is better). We see a great improvement.\n",
        "\n",
        "![](https://raw.githubusercontent.com/mlelarge/dataflowr/master/PlutonAI/img/model_scatter.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1-qdjrkB6Nu"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=[all_y[i,j] for i,j in enumerate(last_indices)],y=[pred_fail[i,j] for i,j in enumerate(last_indices)],dropna=True,kind=\"kde\", n_levels=30, color=\"g\");\n",
        "plot.ax_joint.plot([0,150], [0,150], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuzDlaPiB6Nw"
      },
      "outputs": [],
      "source": [
        "plot = sns.jointplot(x=all_y,y=pred_fail,dropna=True,kind=\"kde\", space=0, color=\"g\");\n",
        "plot.ax_joint.plot([0,200], [0,200], 'b-', linewidth = 2);\n",
        "plot.set_axis_labels('true', 'predicted');"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}