{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benj-admin/MAP_X/blob/main/TP/TP02_Full_training_loop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ed4f724",
      "metadata": {
        "id": "1ed4f724"
      },
      "source": [
        "# TP02 - Cross entropy loss and handwritten character recognition\n",
        "In this practical, we will first **re-implement the cross entropy loss**, and then write our first proper **training and testing pipeline** for a **handwritten character recognition task** (small version of the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset).\n",
        "\n",
        "**FYI:** GPUs are not necessary for this practical."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "from torch import nn\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ],
      "metadata": {
        "id": "GGNhWCbT4qFH",
        "outputId": "b822039f-46e1-4932-b7f4-115ec1ebe878",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "GGNhWCbT4qFH",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: False \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part A - Reimplementing loss functions\n",
        "\n",
        "## A.0 - Combining losses\n",
        "First, we recall that, for a batch of score vectors $s\\in\\mathbb{R}^{n\\times C}$ and true labels $y\\in[1,C]^n$, **cross entropy** is defined as\n",
        "$$CE(s, y) = -\\frac{1}{n}\\sum_{i=1}^n \\log\\left( \\mbox{softmax}(s_i)_{y_i} \\right)$$\n",
        "\n",
        "where $\\mbox{softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^n e^{x_j}}$ is the probability associated to class $i\\in[1,C]$ for a score vector $x\\in\\mathbb{R}^C$.\n",
        "\n",
        "Let's try to compute cross-entropy in three different ways (see the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)):\n",
        "1. Using `nn.CrossEntropyLoss()`.\n",
        "2. Using `nn.NLLLoss()` and `nn.LogSoftmax()`.\n",
        "3. Using `nn.NLLLoss()` and `nn.Softmax()`.\n",
        "\n",
        "Check that the output is the same for all three methods on Gaussian random scores `torch.randn(n_batch, n_classes)` and random labels `torch.randint(0, n_classes, [n_batch])`, where `n_batch=4` and `n_classes=10`. Note that the scores are real valued vectors while the labels are integers corresponding to the true class."
      ],
      "metadata": {
        "id": "2nes_ZtBoBu0"
      },
      "id": "2nes_ZtBoBu0"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e1b6c172",
      "metadata": {
        "id": "e1b6c172",
        "outputId": "cbf31ef0-cb8a-4b62-8605-40d4aaca54bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 1: 2.2444241046905518\n",
            "Method 2: 2.2444241046905518\n",
            "Method 3: 2.2444241046905518\n"
          ]
        }
      ],
      "source": [
        "n_batch = 4\n",
        "n_classes = 10\n",
        "scores = torch.randn(n_batch, n_classes)\n",
        "true_labels = torch.randint(0, n_classes, [n_batch])\n",
        "\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "log_loss = nn.NLLLoss()\n",
        "softmax = nn.Softmax(dim=1)\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "print(\"Method 1:\", cross_entropy(scores, true_labels).item())\n",
        "print(\"Method 2:\", log_loss(log_softmax(scores), true_labels).item())\n",
        "print(\"Method 3:\", log_loss(torch.log(softmax(scores)), true_labels).item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.1 - Re-implementation\n",
        "Now re-implement cross-entropy using base functions (`torch.log`, `torch.exp`, `torch.sum`, etc...). Verify that your function returns the same value as Pytorch's implementation."
      ],
      "metadata": {
        "id": "TWKaTBVd5ftN"
      },
      "id": "TWKaTBVd5ftN"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Method 4:\", (-torch.mean(torch.log(torch.exp(torch.gather(scores,1,true_labels.unsqueeze(1)))/torch.sum(torch.exp(scores),1)))).item())"
      ],
      "metadata": {
        "id": "EfA-3-E7qwgF",
        "outputId": "37df2f08-3d14-4982-9b97-0d33f49a5599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EfA-3-E7qwgF",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 4: 2.2444241046905518\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A.2 - Stability analysis\n",
        "Softmax probabilities can be relatively unstable due to their use of exponentials. Pytorch implementations thus usually use log probas or logits to avoid overflows or floating point errors. Test all methods (including your own) on Gaussian random scores of standard deviation equal to $100$. Which methods are stable? Why? Is it an issue in practice?"
      ],
      "metadata": {
        "id": "OFG0QfKN7WtO"
      },
      "id": "OFG0QfKN7WtO"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4579b456",
      "metadata": {
        "id": "4579b456",
        "outputId": "0421fa42-0b0a-416d-d2a9-aa23ebb5e0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 1: 144.80511474609375\n",
            "Method 2: 144.80511474609375\n",
            "Method 3: inf\n",
            "Method 4: nan\n"
          ]
        }
      ],
      "source": [
        "n_batch = 4\n",
        "n_classes = 10\n",
        "scores = 100*torch.randn(n_batch, n_classes)\n",
        "true_labels = torch.randint(0, n_classes, [n_batch])\n",
        "\n",
        "cross_entropy = nn.CrossEntropyLoss()\n",
        "log_loss = nn.NLLLoss()\n",
        "softmax = nn.Softmax(dim=1)\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "print(\"Method 1:\", cross_entropy(scores, true_labels).item())\n",
        "print(\"Method 2:\", log_loss(log_softmax(scores), true_labels).item())\n",
        "print(\"Method 3:\", log_loss(torch.log(softmax(scores)), true_labels).item())\n",
        "print(\"Method 4:\", (-torch.mean(torch.log(torch.exp(torch.gather(scores,1,true_labels.unsqueeze(1)))/torch.sum(torch.exp(scores),1)))).item())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-implement a stable version of cross-entropy."
      ],
      "metadata": {
        "id": "Y3y4BfwbBIGy"
      },
      "id": "Y3y4BfwbBIGy"
    },
    {
      "cell_type": "code",
      "source": [
        "scores_stable = scores - torch.max(scores,1,keepdim=True).values\n",
        "print(\"Method 5:\", (-torch.mean((torch.gather(scores_stable,1,true_labels.unsqueeze(1)))-torch.log(torch.sum(torch.exp(scores_stable),1)))).item())"
      ],
      "metadata": {
        "id": "b75Y4Gr_yb2N",
        "outputId": "aad03f0b-da3b-4065-8ba0-3de1bea760d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "b75Y4Gr_yb2N",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Method 5: 144.8050994873047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65e20f5e",
      "metadata": {
        "id": "65e20f5e"
      },
      "source": [
        "# Part B - Handwritten character recognition\n",
        "\n",
        "## B.0 - Dataloader\n",
        "Import `load_digits` from `sklearn.datasets` (see the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html)), load the corresponding dataset and extract the images, data (i.e. flattened version of the images) and targets (i.e. the labels)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f573f740",
      "metadata": {
        "id": "f573f740",
        "outputId": "11fde7ce-cd28-4386-b694-b1ceb5281e6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1797, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from sklearn.datasets import load_digits\n",
        "dataset = load_digits()\n",
        "images = dataset.images\n",
        "data = dataset.data\n",
        "targets = dataset.target\n",
        "X = torch.Tensor(data)\n",
        "y = torch.LongTensor(targets)\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Display the first image and its label."
      ],
      "metadata": {
        "id": "0LJQz-EID1D1"
      },
      "id": "0LJQz-EID1D1"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d2ca7a04",
      "metadata": {
        "id": "d2ca7a04",
        "outputId": "6b08c42b-9284-46fd-c81b-4a6ed70606a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(images[0])\n",
        "y[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, create two PyTorch datasets and dataloaders with a batch size of $50$ for this task: one for the train (80% of the dataset) and one for the test (remaining 20% of the dataset)."
      ],
      "metadata": {
        "id": "76O7R7KxEFJW"
      },
      "id": "76O7R7KxEFJW"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "84d3fdb0",
      "metadata": {
        "id": "84d3fdb0"
      },
      "outputs": [],
      "source": [
        "\n",
        "n_train = int(X.shape[0]*0.8)\n",
        "n_test = X.shape[0] - n_train\n",
        "\n",
        "index = list(range(X.shape[0]))\n",
        "random.shuffle(index)\n",
        "\n",
        "X = X[index]\n",
        "y = y[index]\n",
        "\n",
        "X_train = X[:n_train]\n",
        "y_train = y[:n_train]\n",
        "X_test = X[n_train:]\n",
        "y_test = y[n_train:]\n",
        "\n",
        "train_dataset = torch.utils.data.TensorDataset(X_train,y_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=50, shuffle=True, num_workers =2)\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test,y_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=50, shuffle=True, num_workers =2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.1 - Model creation\n",
        "\n",
        "Create a class MLP that creates an MLP of given width and depth, and use it to create a 3-layer MLP of width $100$. We will assume that `width > 0` and `depth > 0`."
      ],
      "metadata": {
        "id": "RrwYAMMBEUPN"
      },
      "id": "RrwYAMMBEUPN"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "e8353cd9",
      "metadata": {
        "id": "e8353cd9",
        "outputId": "22614b77-3e9e-41b3-daa6-6132307a8f16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=100, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=100, out_features=100, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=100, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, width, depth):\n",
        "        super(MLP, self).__init__()\n",
        "        if depth == 1:\n",
        "            self.layers = nn.Linear(64,10)\n",
        "        else:\n",
        "            layers = [nn.Linear(64, width), nn.ReLU()]\n",
        "            for _ in range(depth - 2):\n",
        "                layers += [nn.Linear(width, width), nn.ReLU()]\n",
        "            layers += [nn.Linear(width, 10)]\n",
        "            self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = MLP(100,3)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.2 - Loss and optimizer\n",
        "Create a cross entropy loss."
      ],
      "metadata": {
        "id": "qeWZ7DeNMG20"
      },
      "id": "qeWZ7DeNMG20"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a85b789e",
      "metadata": {
        "id": "a85b789e"
      },
      "outputs": [],
      "source": [
        "loss = nn.CrossEntropyLoss(reduction = 'sum')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.3 - Training and testing loops\n",
        "Finally, create the functions `train(model, epoch)` and `test(model)` to train (one epoch with SGD and a learning rate of $10^{-3}$) and test your model."
      ],
      "metadata": {
        "id": "ZCnlsh9iMhx_"
      },
      "id": "ZCnlsh9iMhx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4e0fc77",
      "metadata": {
        "id": "f4e0fc77"
      },
      "outputs": [],
      "source": [
        "def train(model,epoch):\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train your model for 200 epochs and display the test loss and accuracy every 10 epochs."
      ],
      "metadata": {
        "id": "NJ4zS7LoURmL"
      },
      "id": "NJ4zS7LoURmL"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "nBmfvtl6UbUe"
      },
      "id": "nBmfvtl6UbUe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.4 - Analyze the results\n",
        "\n",
        "Create a confusion matrix on the train and test datasets using `ConfusionMatrixDisplay.from_predictions` from `sklearn.metrics`. Which digits are confused?"
      ],
      "metadata": {
        "id": "L-qJbBLLYpRc"
      },
      "id": "L-qJbBLLYpRc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55f56821",
      "metadata": {
        "id": "55f56821"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.5 - PCA and TSNE visualizations (optional)\n",
        "\n",
        "To check wether the problem is easily to solve, plot the PCA and TSNE visualization of the dataset, where each digit corresponds to a different color. Are the digits/classes well separated?"
      ],
      "metadata": {
        "id": "3CLIN5ZGaC5i"
      },
      "id": "3CLIN5ZGaC5i"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75d8d001",
      "metadata": {
        "id": "75d8d001"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE ###"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B.6 - Model complexity (optional)\n",
        "How many parameters does the model have? Are they necessary? Try different architectures, including a linear model (use `bias=False` in `nn.Linear` to remove the bias term)."
      ],
      "metadata": {
        "id": "62MFdius1-WF"
      },
      "id": "62MFdius1-WF"
    },
    {
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE ###"
      ],
      "metadata": {
        "id": "rsdoplnn19ek"
      },
      "id": "rsdoplnn19ek",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Django Shell-Plus",
      "language": "python",
      "name": "django_extensions"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}