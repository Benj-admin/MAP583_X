{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benj-admin/MAP583_X/blob/main/Lesson/Tutorial_packing_sequences.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQnZRzVGbLOe"
      },
      "source": [
        "# Minimal tutorial on packing and unpacking sequences in PyTorch\n",
        "# aka how to use `pack_padded_sequence` and  `pad_packed_sequence`\n",
        "\n",
        "This is a jupyter version of [@Tushar-N 's gist](https://gist.github.com/Tushar-N/dfca335e370a2bc3bc79876e6270099e) with comments from [@Harsh Trivedi repo](https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial) and adapted from [the dataflowr website](https://github.com/dataflowr/notebooks/blob/master/Module11/11_Tutorial_packing_sequences.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5JavUAb7bLOh"
      },
      "outputs": [],
      "source": [
        "# from https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial\n",
        "import torch\n",
        "from torch import LongTensor\n",
        "from torch.nn import Embedding, LSTM\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "## We want to run LSTM on a batch of 3 character sequences ['long_str', 'tiny', 'medium']\n",
        "#\n",
        "#     Step 1: Construct Vocabulary\n",
        "#     Step 2: Load indexed data (list of instances, where each instance is list of character indices)\n",
        "#     Step 3: Make Model\n",
        "#  *  Step 4: Pad instances with 0s till max length sequence\n",
        "#  *  Step 5: Sort instances by sequence length in descending order\n",
        "#  *  Step 6: Embed the instances\n",
        "#  *  Step 7: Call pack_padded_sequence with embeded instances and sequence lengths\n",
        "#  *  Step 8: Forward with LSTM\n",
        "#  *  Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector\n",
        "#  *  Summary of Shape Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QddGhqDGbLOk"
      },
      "outputs": [],
      "source": [
        "# We want to run LSTM on a batch following 3 character sequences\n",
        "seqs = ['long_str',  # len = 8\n",
        "        'tiny',      # len = 4\n",
        "        'medium']    # len = 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TlqrY18wbLOl"
      },
      "outputs": [],
      "source": [
        "## Step 1: Construct Vocabulary ##\n",
        "##------------------------------##\n",
        "# make sure <pad> idx is 0\n",
        "vocab = ['<pad>'] + sorted(set([char for seq in seqs for char in seq]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "BZwh-7t3bLOm",
        "outputId": "317b74cf-4f01-4901-a4fb-06682d2950e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<pad>', '_', 'd', 'e', 'g', 'i', 'l', 'm', 'n', 'o', 'r', 's', 't', 'u', 'y']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OZtkGKr7bLOm"
      },
      "outputs": [],
      "source": [
        "## Step 2: Load indexed data (list of instances, where each instance is list of character indices) ##\n",
        "##-------------------------------------------------------------------------------------------------##\n",
        "vectorized_seqs = [[vocab.index(tok) for tok in seq]for seq in seqs]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WWCH67-LbLOn",
        "outputId": "b836389e-684a-41e3-eaa5-0ffa8d18b4e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[6, 9, 8, 4, 1, 11, 12, 10], [12, 5, 8, 14], [7, 3, 2, 5, 13, 7]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "vectorized_seqs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "G0pQQ7VibLOo"
      },
      "outputs": [],
      "source": [
        "## Step 3: Make Model ##\n",
        "##--------------------##\n",
        "embed = Embedding(len(vocab), 4) # embedding_dim = 4\n",
        "lstm = LSTM(input_size=4, hidden_size=5, num_layers=2, batch_first=True) # input_dim = 4, hidden_dim = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YX4mHDi4bLOp"
      },
      "outputs": [],
      "source": [
        "## Step 4: Pad instances with 0s till max length sequence ##\n",
        "##--------------------------------------------------------##\n",
        "\n",
        "# get the length of each seq in your batch\n",
        "seq_lengths = LongTensor(list(map(len, vectorized_seqs)))\n",
        "# seq_lengths => [ 8, 4,  6]\n",
        "# batch_sum_seq_len: 8 + 4 + 6 = 18\n",
        "# max_seq_len: 8\n",
        "\n",
        "seq_tensor = (torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
        "# seq_tensor => [[0 0 0 0 0 0 0 0]\n",
        "#                [0 0 0 0 0 0 0 0]\n",
        "#                [0 0 0 0 0 0 0 0]]\n",
        "\n",
        "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "    seq_tensor[idx, :seqlen] = LongTensor(seq)\n",
        "# seq_tensor => [[ 6  9  8  4  1 11 12 10]          # long_str\n",
        "#                [12  5  8 14  0  0  0  0]          # tiny\n",
        "#                [ 7  3  2  5 13  7  0  0]]         # medium\n",
        "# seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-RrZ71NnbLOq",
        "outputId": "fd88e01d-c278-421a-f2a2-6a676b56e6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([8, 4, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "seq_lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "czq0ROJ0bLOr",
        "outputId": "04fb49b4-ef01-40ca-e39c-fe73b6c2be03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  9,  8,  4,  1, 11, 12, 10],\n",
              "        [12,  5,  8, 14,  0,  0,  0,  0],\n",
              "        [ 7,  3,  2,  5, 13,  7,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "seq_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iBYlHSCWbLOs"
      },
      "outputs": [],
      "source": [
        "## Step 5: Sort instances by sequence length in descending order ##\n",
        "##---------------------------------------------------------------##\n",
        "\n",
        "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
        "seq_tensor = seq_tensor[perm_idx]\n",
        "# seq_tensor.shape : (batch_size X max_seq_len) = (3 X 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xQCHskv5bLOs",
        "outputId": "9f72b300-dc85-481b-a59a-30789f916304",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "perm_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oCbnNat5bLOt",
        "outputId": "28e3c93f-b9a7-480a-9081-3f8142e1b382",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  9,  8,  4,  1, 11, 12, 10],\n",
              "        [ 7,  3,  2,  5, 13,  7,  0,  0],\n",
              "        [12,  5,  8, 14,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "seq_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "v0ASeNN9bLOt"
      },
      "outputs": [],
      "source": [
        "## Step 6: Embed the instances ##\n",
        "##-----------------------------##\n",
        "\n",
        "embedded_seq_tensor = embed(seq_tensor)\n",
        "# embedded_seq_tensor.shape : (batch_size X max_seq_len X embedding_dim) = (3 X 8 X 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JaQ9pZNTbLOu",
        "outputId": "13b08a9b-6f1c-4138-bc1b-54c03048cc03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.7212e-02, -1.8416e-01,  1.4720e+00,  1.2781e+00],\n",
              "         [-5.2917e-01,  8.1698e-01, -3.5535e-01,  9.0872e-01],\n",
              "         [ 9.2419e-01,  1.1221e+00,  5.3511e-01, -2.7484e-02],\n",
              "         [-6.2186e-01,  3.8420e-02, -1.5629e+00,  1.7817e+00],\n",
              "         [-7.6745e-01, -9.3460e-01,  4.4326e-01, -4.6463e-01],\n",
              "         [-6.3583e-02,  1.2693e+00, -1.3119e+00, -1.9940e+00],\n",
              "         [-6.3914e-01, -1.3176e-01, -1.4167e-01,  5.7377e-01],\n",
              "         [ 3.0209e-01, -2.0734e+00, -1.9709e+00, -4.1188e-01]],\n",
              "\n",
              "        [[ 3.4736e-01, -8.8285e-01, -3.2616e+00,  6.5706e-01],\n",
              "         [-6.2543e-02, -2.7879e-01, -8.7413e-01, -6.0503e-02],\n",
              "         [-1.4458e+00,  5.9985e-01, -9.4143e-01, -6.4183e-01],\n",
              "         [ 9.0825e-01, -1.6225e+00, -9.9412e-01,  8.9833e-01],\n",
              "         [ 1.4871e+00, -5.3385e-02, -2.0026e-01, -1.2087e+00],\n",
              "         [ 3.4736e-01, -8.8285e-01, -3.2616e+00,  6.5706e-01],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00]],\n",
              "\n",
              "        [[-6.3914e-01, -1.3176e-01, -1.4167e-01,  5.7377e-01],\n",
              "         [ 9.0825e-01, -1.6225e+00, -9.9412e-01,  8.9833e-01],\n",
              "         [ 9.2419e-01,  1.1221e+00,  5.3511e-01, -2.7484e-02],\n",
              "         [ 7.4403e-01,  1.0089e+00,  4.3065e-01, -4.3929e-01],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00],\n",
              "         [ 2.4081e-03,  4.0468e-01,  2.5185e-01, -2.3913e+00]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "embedded_seq_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "g_Vi088obLOu",
        "outputId": "19de5743-85f4-45ef-967a-feff7d08f6cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "embedded_seq_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "av6jxPJKbLOv"
      },
      "outputs": [],
      "source": [
        "## Step 7: Call pack_padded_sequence with embeded instances and sequence lengths ##\n",
        "##-------------------------------------------------------------------------------##\n",
        "\n",
        "packed_input = pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
        "# packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "# packed_input.data.shape : (batch_sum_seq_len X embedding_dim) = (18 X 4)\n",
        "#\n",
        "# packed_input.batch_sizes => [ 3,  3,  3,  3,  2,  2,  1,  1]\n",
        "# visualization :\n",
        "# l  o  n  g  _  s  t  r   #(long_str)\n",
        "# m  e  d  i  u  m         #(medium)\n",
        "# t  i  n  y               #(tiny)\n",
        "# 3  3  3  3  2  2  1  1   (sum = 18 [batch_sum_seq_len])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7kSd-i3_bLOw",
        "outputId": "d732e1d5-26ea-46be-bb60-2d10a6ec702c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "packed_input.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XDWnr4KEbLOw"
      },
      "outputs": [],
      "source": [
        "## Step 8: Forward with LSTM ##\n",
        "##---------------------------##\n",
        "\n",
        "packed_output, (ht, ct) = lstm(packed_input)\n",
        "# packed_output (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "# packed_output.data.shape : (batch_sum_seq_len X hidden_dim) = (18 X 5)\n",
        "\n",
        "# packed_output.batch_sizes => [ 3,  3,  3,  3,  2,  2,  1,  1] (same as packed_input.batch_sizes)\n",
        "# visualization :\n",
        "# l  o  n  g  _  s  t  r   #(long_str)\n",
        "# m  e  d  i  u  m         #(medium)\n",
        "# t  i  n  y               #(tiny)\n",
        "# 3  3  3  3  2  2  1  1   (sum = 18 [batch_sum_seq_len])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4-HZ3rR5bLOx",
        "outputId": "5fda6c48-5658-4380-838b-eb2ef395d979",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "packed_output.data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "JNICVFNgbLOx",
        "outputId": "79a718fa-7bf9-44bb-da66-41325cbc7ab4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.4507,  0.3145,  0.1443, -0.2201,  0.3672],\n",
              "         [ 0.2193,  0.3463,  0.0641, -0.0828,  0.5242],\n",
              "         [ 0.1499,  0.1867, -0.1596, -0.0195,  0.2578]],\n",
              "\n",
              "        [[-0.0088, -0.0409, -0.0770,  0.0813, -0.0619],\n",
              "         [-0.0292, -0.0492, -0.0912,  0.1028, -0.0431],\n",
              "         [ 0.0045, -0.0472, -0.0574,  0.1133, -0.0490]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "ht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "-JnOtkKCbLOx",
        "outputId": "82a31921-72d6-4ff0-8be6-7692733d97ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "ht.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DRTXOr9ibLOy",
        "outputId": "45ca06f7-91f4-4339-b80e-0efd6aed9ba8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.6435,  0.5615,  0.2564, -0.4226,  0.6030],\n",
              "         [ 0.2882,  0.9806,  0.1696, -0.3333,  0.7945],\n",
              "         [ 0.3515,  0.4045, -0.3672, -0.0361,  0.4653]],\n",
              "\n",
              "        [[-0.0150, -0.0859, -0.1337,  0.1347, -0.1911],\n",
              "         [-0.0482, -0.0981, -0.1607,  0.1683, -0.1249],\n",
              "         [ 0.0070, -0.0922, -0.1011,  0.1852, -0.1497]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "ct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "S91FvW63bLOy",
        "outputId": "214d639f-8f62-4690-e3a0-5c2da0de4296",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "ct.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PAn465xQbLOz"
      },
      "outputs": [],
      "source": [
        "## Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector ##\n",
        "##------------------------------------------------------------------------------------##\n",
        "\n",
        "# unpack your output if required\n",
        "output, input_sizes = pad_packed_sequence(packed_output, batch_first=True)\n",
        "# output:\n",
        "# output.shape : ( batch_size X max_seq_len X hidden_dim) = (3 X 8 X 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NQT6l7NxbLOz",
        "outputId": "cef4d260-ea45-4671-c200-7e74e0a8d8da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0015,  0.0092, -0.0283,  0.0632, -0.0510],\n",
              "         [-0.0059,  0.0013, -0.0549,  0.0985, -0.0620],\n",
              "         [-0.0026, -0.0195, -0.0565,  0.1178, -0.0583],\n",
              "         [-0.0230, -0.0254, -0.0815,  0.1261, -0.0534],\n",
              "         [-0.0004, -0.0448, -0.0941,  0.1046, -0.0471],\n",
              "         [ 0.0500, -0.0715, -0.0660,  0.0944, -0.0432],\n",
              "         [ 0.0423, -0.0588, -0.0665,  0.0957, -0.0503],\n",
              "         [-0.0088, -0.0409, -0.0770,  0.0813, -0.0619]],\n",
              "\n",
              "        [[ 0.0158, -0.0090, -0.0381,  0.0692, -0.0366],\n",
              "         [ 0.0222, -0.0239, -0.0638,  0.0959, -0.0468],\n",
              "         [ 0.0495, -0.0454, -0.0606,  0.1087, -0.0464],\n",
              "         [ 0.0013, -0.0338, -0.0863,  0.1034, -0.0528],\n",
              "         [ 0.0197, -0.0631, -0.0834,  0.0884, -0.0425],\n",
              "         [-0.0292, -0.0492, -0.0912,  0.1028, -0.0431],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.0240, -0.0058, -0.0214,  0.0593, -0.0469],\n",
              "         [-0.0120, -0.0077, -0.0597,  0.0820, -0.0615],\n",
              "         [-0.0109, -0.0282, -0.0659,  0.1032, -0.0544],\n",
              "         [ 0.0045, -0.0472, -0.0574,  0.1133, -0.0490],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
              "       grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sXDHks78bLO0",
        "outputId": "2fe70139-e53f-45f5-c5c8-78a3ca53351d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 8, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "output.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ezBxfB8CbLO0",
        "outputId": "9c05381c-3501-4c6e-fd9e-ec0b5ca19574",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0088, -0.0409, -0.0770,  0.0813, -0.0619],\n",
            "        [-0.0292, -0.0492, -0.0912,  0.1028, -0.0431],\n",
            "        [ 0.0045, -0.0472, -0.0574,  0.1133, -0.0490]],\n",
            "       grad_fn=<SelectBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# Or if you just want the final hidden state?\n",
        "print(ht[-1])\n",
        "\n",
        "## Summary of Shape Transformations ##\n",
        "##----------------------------------##\n",
        "\n",
        "# (batch_size X max_seq_len X embedding_dim) --> Sort by seqlen ---> (batch_size X max_seq_len X embedding_dim)\n",
        "# (batch_size X max_seq_len X embedding_dim) --->      Pack     ---> (batch_sum_seq_len X embedding_dim)\n",
        "# (batch_sum_seq_len X embedding_dim)        --->      LSTM     ---> (batch_sum_seq_len X hidden_dim)\n",
        "# (batch_sum_seq_len X hidden_dim)           --->    UnPack     ---> (batch_size X max_seq_len X hidden_dim)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dldiy",
      "language": "python",
      "name": "dldiy"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}