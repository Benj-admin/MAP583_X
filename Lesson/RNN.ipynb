{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benj-admin/MAP583_X/blob/main/Lesson/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8ecFD9cgjM9"
      },
      "source": [
        "# RNNs on a simple example\n",
        "\n",
        "This jupyter notebook allows you to reproduce and explore the results presented in the [dataflowr lecture on RNN](https://dataflowr.github.io/slides/module11.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Pc29CvyHgjNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acbba440-4bec-4d69-b1bd-5c510f64e5d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using gpu: True \n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import scipy.special\n",
        "from scipy.special import binom\n",
        "import time\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "utb4MovzgjNe"
      },
      "outputs": [],
      "source": [
        "def running_mean(x, N):\n",
        "    cumsum = np.cumsum(np.insert(x, 0, 0))\n",
        "    return (cumsum[N:] - cumsum[:-N]) / float(N)\n",
        "\n",
        "def Catalan(k):\n",
        "    return binom(2*k,k)/(k+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ytku22GgjOB"
      },
      "source": [
        "## 1. Generation a dataset\n",
        "\n",
        "We have a problem, where we need to generate a dataset made of valid parenthesis strings but also invalid parenthesis string. You can skip to the end of this section to see how parenthesis strings are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "QfpbFNT1gjOF"
      },
      "outputs": [],
      "source": [
        "seq_max_len = 20\n",
        "seq_min_len = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHAs_VxrgjOS"
      },
      "source": [
        "### generating positive examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DKlEMULfgjOX"
      },
      "outputs": [],
      "source": [
        "# convention: +1 opening parenthesis and -1 closing parenthesis\n",
        "\n",
        "def all_parent(n, a, k=-1):\n",
        "    global res\n",
        "    if k==n-1 and sum(a) == 0:\n",
        "        res.append(a.copy())\n",
        "    elif k==n-1:\n",
        "        pass\n",
        "    else:\n",
        "        k += 1\n",
        "        if sum(a) > 0:\n",
        "            a[k] = 1\n",
        "            all_parent(n,a,k)\n",
        "\n",
        "            a[k] = -1\n",
        "            all_parent(n,a,k)\n",
        "            a[k] = 0\n",
        "        else:\n",
        "            a[k] = 1\n",
        "            all_parent(n,a,k)\n",
        "            a[k] = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFcYswvXgjOl"
      },
      "source": [
        "### generating negative examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ZXm1-wS9gjOp"
      },
      "outputs": [],
      "source": [
        "def all_parent_mistake(n, a, k=-1):\n",
        "    global res\n",
        "    if k==n-1 and sum(a) >= -1 and sum(a) <= 1 and min(np.cumsum(a))<0:\n",
        "        res.append(a.copy())\n",
        "    elif sum(a) > n-k:\n",
        "        pass\n",
        "    elif k==n-1:\n",
        "        pass\n",
        "    else:\n",
        "        k += 1\n",
        "        if sum(a) >= -1 and k != 0:\n",
        "            a[k] = 1\n",
        "            all_parent_mistake(n,a,k)\n",
        "\n",
        "            a[k] = -1\n",
        "            all_parent_mistake(n,a,k)\n",
        "            a[k] = 0\n",
        "        else:\n",
        "            a[k] = 1\n",
        "            all_parent_mistake(n,a,k)\n",
        "            a[k] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ePYlXZaYgjO6"
      },
      "outputs": [],
      "source": [
        "# numbering the parentheses\n",
        "# example: seq of len 6\n",
        "# ( ( ( ) ) )\n",
        "# 0 1 2 4 5 6\n",
        "# we always have ( + ) = seq_len\n",
        "# 'wrong' parentheses are always closing and numbered as:\n",
        "# ) )\n",
        "# 7 8\n",
        "\n",
        "def reading_par(l, n):\n",
        "    res = [0]*len(l)\n",
        "    s = []\n",
        "    n_plus = -1\n",
        "    n_moins = n+1\n",
        "    c = 0\n",
        "    for i in l:\n",
        "        if i == 1:\n",
        "            n_plus += 1\n",
        "            s.append(n_plus)\n",
        "            res[c] = n_plus\n",
        "            c += 1\n",
        "        else:\n",
        "            try:\n",
        "                res[c] = n-s.pop()\n",
        "            except:\n",
        "                res[c] = n_moins\n",
        "                n_moins += 1\n",
        "            c += 1\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "dA0MR3f7gjPN"
      },
      "outputs": [],
      "source": [
        "all_par = OrderedDict()\n",
        "for n in range(seq_min_len,seq_max_len+1,2):\n",
        "    a = [0]*n\n",
        "    res = []\n",
        "    all_parent(n=n,a=a,k=-1)\n",
        "    all_par[n] = [reading_par(k,n) for k in res]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "JfMc7FvagjPi"
      },
      "outputs": [],
      "source": [
        "all_par_mist = OrderedDict()\n",
        "for n in range(seq_min_len,seq_max_len+1,2):\n",
        "    a = [0]*n\n",
        "    res = []\n",
        "    all_parent_mistake(n=n,a=a,k=-1)\n",
        "    all_par_mist[n] = [reading_par(k,n) for k in res]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "7PtA8pQIgjP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7de92b30-2491-43b8-a547-5fa0be73c4f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 2, 4, 5, 6],\n",
              " [0, 1, 5, 2, 4, 6],\n",
              " [0, 1, 5, 6, 2, 4],\n",
              " [0, 6, 1, 2, 4, 5],\n",
              " [0, 6, 1, 5, 2, 4]]"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "all_par[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "26eGcBytgjQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "516d91de-c6da-4520-9746-267f2700e684"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 5, 6, 7, 2],\n",
              " [0, 6, 1, 5, 7, 2],\n",
              " [0, 6, 7, 1, 2, 4],\n",
              " [0, 6, 7, 1, 5, 2],\n",
              " [0, 6, 7, 8, 1, 2]]"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "all_par_mist[6]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCo1lHQpgjQT"
      },
      "source": [
        "### number of negative examples by length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "mdr-aeg8gjQX"
      },
      "outputs": [],
      "source": [
        "long_mist = {i:len(l) for (i,l) in zip(all_par_mist.keys(),all_par_mist.values())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "7gWfeHiEgjQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a2e5cb-e645-4ba2-a10b-59d8edb0436e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 1, 6: 5, 8: 20, 10: 75, 12: 275, 14: 1001, 16: 3640, 18: 13260, 20: 48450}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "long_mist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq8iVHxDgjQm"
      },
      "source": [
        "### number of positive examples by length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "kxzqq0JCgjQo"
      },
      "outputs": [],
      "source": [
        "Catalan_num = {i:len(l) for (i,l) in zip(all_par.keys(),all_par.values())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "WmRoddtQgjQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0979f7-d216-42b3-c7f1-a8cec2263d61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{4: 2, 6: 5, 8: 14, 10: 42, 12: 132, 14: 429, 16: 1430, 18: 4862, 20: 16796}"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "Catalan_num"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzCECk4EgjQ5"
      },
      "source": [
        "Sanity check, see [Catalan numbers](https://en.wikipedia.org/wiki/Catalan_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "8Thfdkm8gjQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5662d65-93da-4387-a6ea-6e11e065d47e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(4, np.float64(2.0)),\n",
              " (6, np.float64(5.0)),\n",
              " (8, np.float64(14.0)),\n",
              " (10, np.float64(42.0)),\n",
              " (12, np.float64(132.0)),\n",
              " (14, np.float64(429.0)),\n",
              " (16, np.float64(1430.0)),\n",
              " (18, np.float64(4862.0)),\n",
              " (20, np.float64(16796.0))]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "[(2*i,Catalan(i)) for i  in range(2,int(seq_max_len/2)+1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "qri2vYemgjRF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1a09ea0-a11d-476e-e6eb-b359bbf8f8f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(174113843800.0)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# nombre de suites correctes de longueur entre 4 et 10, alphabet de taille nb_symbol.\n",
        "nb_symbol = 10\n",
        "np.sum([Catalan(i)*int(nb_symbol/2)**i for i in range(2,int(seq_max_len/2)+1)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "LVc13MYfgjRR"
      },
      "outputs": [],
      "source": [
        "class SequenceGenerator():\n",
        "    def __init__(self, nb_symbol = 10, seq_min_len = 4, seq_max_len = 10):\n",
        "        self.nb_symbol = nb_symbol\n",
        "        self.seq_min_len = seq_min_len\n",
        "        self.seq_max_len = seq_max_len\n",
        "        self.population = [i for i in range(int(nb_symbol/2))]\n",
        "\n",
        "    def generate_pattern(self):\n",
        "        len_r = random.randint(self.seq_min_len/2,self.seq_max_len/2)\n",
        "        pattern = random.choices(self.population,k=len_r)\n",
        "        return pattern + pattern[::-1]\n",
        "\n",
        "    def generate_pattern_parenthesis(self, len_r = None):\n",
        "        if len_r == None:\n",
        "            len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,Catalan_num[len_r]-1)\n",
        "        res = [pattern[i] if i <= len_r/2 else self.nb_symbol-1-pattern[len_r-i] for i in all_par[len_r][ind_r]]\n",
        "        return res\n",
        "\n",
        "    def generate_parenthesis_false(self):\n",
        "        len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,long_mist[len_r]-1)\n",
        "        res = [pattern[i] if i <= len_r/2\n",
        "               else  self.nb_symbol-1-pattern[len_r-i] if i<= len_r\n",
        "               else self.nb_symbol-1-pattern[i-len_r] for i in all_par_mist[len_r][ind_r]]\n",
        "        return res\n",
        "\n",
        "    def generate_hard_parenthesis(self, len_r = None):\n",
        "        if len_r == None:\n",
        "            len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,Catalan_num[len_r]-1)\n",
        "        res = [pattern[i] if i <= len_r/2 else self.nb_symbol-1-pattern[len_r-i] for i in all_par[len_r][ind_r]]\n",
        "\n",
        "        if len_r == None:\n",
        "            len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,Catalan_num[len_r]-1)\n",
        "        res2 = [pattern[i] if i <= len_r/2 else self.nb_symbol-1-pattern[len_r-i] for i in all_par[len_r][ind_r]]\n",
        "        return res + res2\n",
        "\n",
        "    def generate_hard_nonparenthesis(self, len_r = None):\n",
        "        if len_r == None:\n",
        "            len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,long_mist[len_r]-1)\n",
        "        res = [pattern[i] if i <= len_r/2\n",
        "               else  self.nb_symbol-1-pattern[len_r-i] if i<= len_r\n",
        "               else self.nb_symbol-1-pattern[i-len_r] for i in all_par_mist[len_r][ind_r]]\n",
        "\n",
        "        if len_r == None:\n",
        "            len_r = int(2*random.randint(self.seq_min_len//2,self.seq_max_len//2))\n",
        "        pattern = np.random.choice(self.population,size=int(len_r/2),replace=True)\n",
        "        ind_r = random.randint(0,Catalan_num[len_r]-1)\n",
        "        res2 = [pattern[i] if i <= len_r/2 else self.nb_symbol-1-pattern[len_r-i] for i in all_par[len_r][ind_r]]\n",
        "        return  res +[self.nb_symbol-1-pattern[0]]+ res2\n",
        "\n",
        "    def generate_false(self):\n",
        "        popu = [i for i in range(self.nb_symbol)]\n",
        "        len = random.randint(self.seq_min_len//2,self.seq_max_len//2)\n",
        "        return random.choices(popu,k=len) + random.choices(popu,k=len)\n",
        "\n",
        "    def generate_label(self, x):\n",
        "        l = int(len(x)/2)\n",
        "        return 1 if x[:l] == x[:l-1:-1] else 0\n",
        "\n",
        "    def generate_label_parenthesis(self, x):\n",
        "        s = []\n",
        "        label = 1\n",
        "        lenx = len(x)\n",
        "        for i in x:\n",
        "            if s == [] and i < self.nb_symbol/2:\n",
        "                s.append(i)\n",
        "            elif s == [] and i >= self.nb_symbol/2:\n",
        "                label = 0\n",
        "                break\n",
        "            elif i == self.nb_symbol-1-s[-1]:\n",
        "                s.pop()\n",
        "            else:\n",
        "                s.append(i)\n",
        "        if s != []:\n",
        "            label = 0\n",
        "        return label\n",
        "\n",
        "    def one_hot(self,seq):\n",
        "        one_hot_seq = []\n",
        "        for s in seq:\n",
        "            one_hot = [0 for _ in range(self.nb_symbol)]\n",
        "            one_hot[s] = 1\n",
        "            one_hot_seq.append(one_hot)\n",
        "        return one_hot_seq\n",
        "\n",
        "    def generate_input(self, len_r = None, true_parent = False, hard_false = True):\n",
        "        if true_parent:\n",
        "            seq = self.generate_pattern_parenthesis(len_r)\n",
        "        elif bool(random.getrandbits(1)):\n",
        "            seq = self.generate_pattern_parenthesis(len_r)\n",
        "        else:\n",
        "            if hard_false:\n",
        "                seq = self.generate_parenthesis_false()\n",
        "            else:\n",
        "                seq = self.generate_false()\n",
        "        return torch.from_numpy(np.array(self.one_hot(seq))).type(torch.FloatTensor).to(device), torch.from_numpy(np.array([self.generate_label_parenthesis(seq)])).to(device)\n",
        "\n",
        "    def generate_input_hard(self,true_parent = False):\n",
        "        if true_parent:\n",
        "            seq = self.generate_hard_parenthesis(self.seq_max_len)\n",
        "        elif bool(random.getrandbits(1)):\n",
        "            seq = self.generate_hard_parenthesis(self.seq_max_len)\n",
        "        else:\n",
        "            seq = self.generate_hard_nonparenthesis(self.seq_max_len)\n",
        "\n",
        "        return torch.from_numpy(np.array(self.one_hot(seq))).type(torch.FloatTensor).to(device), torch.from_numpy(np.array([self.generate_label_parenthesis(seq)])).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "ivBE7UIYgjRc"
      },
      "outputs": [],
      "source": [
        "nb_symbol = 10\n",
        "generator = SequenceGenerator(nb_symbol = nb_symbol, seq_min_len = seq_min_len, seq_max_len = seq_max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Dj5YgzvXgjRq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d168abe-f70e-41db-d1cb-40d8fbeb9aa4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[np.int64(3),\n",
              " np.int64(4),\n",
              " np.int64(5),\n",
              " np.int64(4),\n",
              " np.int64(0),\n",
              " np.int64(9),\n",
              " np.int64(5),\n",
              " np.int64(6),\n",
              " np.int64(1),\n",
              " np.int64(8)]"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "generator.generate_pattern_parenthesis()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "lbKlAmE_gjRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b846fca-4909-457b-c052-b6ed3083e9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[np.int64(3), np.int64(6), np.int64(9), np.int64(0), np.int64(9), np.int64(0), np.int64(1), np.int64(8), np.int64(0), np.int64(1), np.int64(8), np.int64(9), np.int64(9), np.int64(1), np.int64(4), np.int64(5)]\n"
          ]
        }
      ],
      "source": [
        "x = generator.generate_parenthesis_false()\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "2kdSGWGCgjR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60719102-bc4a-41ee-b7f9-9f19564f8fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "generator.generate_label_parenthesis(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "4hL2UnY6gjSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f261b135-fb78-4516-f88b-46b3153ec469"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "         [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]], device='cuda:0'),\n",
              " tensor([0], device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "generator.generate_input()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkOTjH01gjSN"
      },
      "source": [
        "## 2. First RNN: [Elman network](https://mlelarge.github.io/dataflowr-slides/PlutonAI/lesson7.html#16)\n",
        "\n",
        "Initial hidden state: $h_0 =0$\n",
        "\n",
        "Update:\n",
        "\n",
        "$$\n",
        "h_t = \\mathrm{ReLU}(W_{xh} x_t + W_{hh} h_{t-1} + b_h)\n",
        "$$\n",
        "\n",
        "Final prediction:\n",
        "\n",
        "$$\n",
        "y_T = W_{hy} h_T + b_y.\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "bLIQlP1QgjSP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class RecNet(nn.Module):\n",
        "    def __init__(self, dim_input=10, dim_recurrent=50, dim_output=2):\n",
        "        super(RecNet, self).__init__()\n",
        "        self.fc_x2h = nn.Linear(dim_input, dim_recurrent)\n",
        "        self.fc_h2h = nn.Linear(dim_recurrent, dim_recurrent, bias = False)\n",
        "        self.fc_h2y = nn.Linear(dim_recurrent, dim_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x.new_zeros(1, self.fc_h2y.weight.size(1))\n",
        "        for t in range(x.size(0)):\n",
        "            h = torch.relu(self.fc_x2h(x[t,:]) + self.fc_h2h(h))\n",
        "        return self.fc_h2y(h)\n",
        "\n",
        "RNN = RecNet(dim_input = nb_symbol).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "AcbhSU5ggjSW"
      },
      "outputs": [],
      "source": [
        "nb_train, nb_test = 40000, 1000\n",
        "\n",
        "def train(model, data_gen):\n",
        "    cross_entropy = nn.CrossEntropyLoss()\n",
        "    learning_rate = 1e-3\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "    loss_t = []\n",
        "    corrects =[]\n",
        "    labels = []\n",
        "    start = time.time()\n",
        "    for k in tqdm(range(nb_train)):\n",
        "        input, label = data_gen()\n",
        "        output = model(input)\n",
        "        loss = cross_entropy(output, label)\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        corrects.append(preds.item() == label.item())\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_t.append(loss.item())\n",
        "        labels.append(label.item())\n",
        "    print(time.time() - start)\n",
        "    return loss_t, corrects, labels\n",
        "\n",
        "def test(model, data_gen):\n",
        "    corrects_test =[]\n",
        "    labels_test = []\n",
        "    for k in tqdm(range(nb_test)):\n",
        "        input, label = data_gen()\n",
        "        output = model(input)\n",
        "        preds = torch.argmax(output, dim=1)\n",
        "        corrects_test.append(preds.item() == label.item())\n",
        "        labels_test.append(label.item())\n",
        "    return corrects_test, labels_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NilV4syzgjSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8917537e-bf62-4bb4-9e7f-c2dbb817cc94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 10381/40000 [00:53<02:18, 214.26it/s]"
          ]
        }
      ],
      "source": [
        "loss_t, corrects, _ = train(RNN, lambda: generator.generate_input(hard_false = False))\n",
        "\n",
        "plt.plot(running_mean(loss_t, int(nb_train/100)))\n",
        "plt.show()\n",
        "plt.plot(running_mean(corrects, int(nb_train/100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdgtK_tGZvJR"
      },
      "source": [
        "Accuracy on valid parenthesis strings only:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2A1jCLJgjS5"
      },
      "outputs": [],
      "source": [
        "corrects_test, labels_test = test(RNN, lambda: generator.generate_input(len_r=seq_max_len,true_parent=True))\n",
        "np.sum(corrects_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjT6sbUSZvJV"
      },
      "source": [
        "Accuracy on a test set (similar to the training set):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Geelj-5XgjTM"
      },
      "outputs": [],
      "source": [
        "corrects_test, labels_test = test(RNN, lambda: generator.generate_input(len_r=seq_max_len, hard_false = True))\n",
        "np.sum(corrects_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rioM-_UkZvJa"
      },
      "source": [
        "Accuracy on a test set of hard instances, i.e. instances longer than those seen during the training :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br6HRXOhgjTc"
      },
      "outputs": [],
      "source": [
        "correctsh_test, labelsh_test = test(RNN, lambda: generator.generate_input_hard())\n",
        "np.sum(correctsh_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOPC3MomZvJg"
      },
      "source": [
        "It looks like our network is always prediciting a valid label for long sequences:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6ZM_4c2gjTw"
      },
      "outputs": [],
      "source": [
        "correctsh_test, labelsh_test = test(RNN, lambda: generator.generate_input_hard(true_parent=True))\n",
        "np.sum(correctsh_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvaIEg6igjT3"
      },
      "source": [
        "## 3. [RNN with Gating](https://mlelarge.github.io/dataflowr-slides/PlutonAI/lesson7.html#20)\n",
        "\n",
        "$$\n",
        "\\overline{h}_t = \\mathrm{ReLU}(W_{xh} x_t + W_{hh} h_{t-1} + b_h)\n",
        "$$\n",
        "Forget gate:\n",
        "$$\n",
        "z_t = \\mathrm{sigm}(W_{xz} x_t + W_{hz}h_{t-1}+b_z)\n",
        "$$\n",
        "Hidden state:\n",
        "$$\n",
        "h_t = z_t\\odot h_{t-1} +(1-z_t) \\odot \\overline{h}_t\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOiH5WsLgjT5"
      },
      "outputs": [],
      "source": [
        "class RecNetGating(nn.Module):\n",
        "    def __init__(self, dim_input=10, dim_recurrent=50, dim_output=2):\n",
        "        super(RecNetGating, self).__init__()\n",
        "        self.fc_x2h = nn.Linear(dim_input, dim_recurrent)\n",
        "        self.fc_h2h = nn.Linear(dim_recurrent, dim_recurrent, bias = False)\n",
        "        self.fc_x2z = nn.Linear(dim_input, dim_recurrent)\n",
        "        self.fc_h2z = nn.Linear(dim_recurrent,dim_recurrent, bias = False)\n",
        "        self.fc_h2y = nn.Linear(dim_recurrent, dim_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x.new_zeros(1, self.fc_h2y.weight.size(1))\n",
        "        for t in range(x.size(0)):\n",
        "            z = torch.sigmoid(self.fc_x2z(x[t,:])+self.fc_h2z(h))\n",
        "            hb = torch.relu(self.fc_x2h(x[t,:]) + self.fc_h2h(h))\n",
        "            h = z * h + (1-z) * hb\n",
        "        return self.fc_h2y(h)\n",
        "\n",
        "RNNG = RecNetGating(dim_input = nb_symbol).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZuKhEg-gjUB"
      },
      "outputs": [],
      "source": [
        "loss_tG, correctsG, _ = train(RNNG, lambda: generator.generate_input(hard_false = False))\n",
        "\n",
        "plt.plot(running_mean(loss_t, int(nb_train/100)))\n",
        "plt.plot(running_mean(loss_tG, int(nb_train/100)))\n",
        "plt.show()\n",
        "plt.plot(running_mean(corrects, int(nb_train/100)))\n",
        "plt.plot(running_mean(correctsG, int(nb_train/100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wOL4IOo8ZvJx"
      },
      "source": [
        "Accuracy on valid parenthesis strings only:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKF7r8dSgjUc"
      },
      "outputs": [],
      "source": [
        "correctsG_test, labelsG_test = test(RNNG, lambda: generator.generate_input(len_r=seq_max_len,true_parent=True))\n",
        "np.sum(correctsG_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OydDhUHiZvJ2"
      },
      "source": [
        "Accuracy on a test set (similar to the training set):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdWoh4UTgjUv"
      },
      "outputs": [],
      "source": [
        "correctsG_test, labelsG_test = test(RNNG, lambda: generator.generate_input(len_r=seq_max_len, hard_false = True))\n",
        "np.sum(correctsG_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDiAHxCIZvJ6"
      },
      "source": [
        "Accuracy on a test set of hard instances, i.e. instances longer than those seen during the training :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUMHjsXrgjVB"
      },
      "outputs": [],
      "source": [
        "correctshG_test, labelshG_test = test(RNNG, lambda: generator.generate_input_hard())\n",
        "np.sum(correctshG_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GO-LItVgjVN"
      },
      "source": [
        "## 4. [LSTM](https://mlelarge.github.io/dataflowr-slides/PlutonAI/lesson7.html#27)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gTATkvrgjVR"
      },
      "outputs": [],
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, dim_input=10, dim_recurrent=50, num_layers=4, dim_output=2):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size = dim_input,\n",
        "                           hidden_size = dim_recurrent,\n",
        "                           num_layers = num_layers)\n",
        "        self.fc_o2y = nn.Linear(dim_recurrent,dim_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(1)\n",
        "        output, _ = self.lstm(x)\n",
        "        output = output.squeeze(1)\n",
        "        output = output.narrow(0, output.size(0)-1,1)\n",
        "        return self.fc_o2y(F.relu(output))\n",
        "\n",
        "lstm = LSTMNet(dim_input = nb_symbol).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkjccxdsgjVX"
      },
      "outputs": [],
      "source": [
        "input, label = generator.generate_input()\n",
        "lstm(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp2KI_eSgjVk"
      },
      "outputs": [],
      "source": [
        "loss_tL, correctsL, _ = train(lstm, lambda: generator.generate_input(hard_false = False))\n",
        "\n",
        "plt.plot(running_mean(loss_t, int(nb_train/100)))\n",
        "plt.plot(running_mean(loss_tG, int(nb_train/100)))\n",
        "plt.plot(running_mean(loss_tL, int(nb_train/100)))\n",
        "plt.show()\n",
        "plt.plot(running_mean(corrects, int(nb_train/100)))\n",
        "plt.plot(running_mean(correctsG, int(nb_train/100)))\n",
        "plt.plot(running_mean(correctsL, int(nb_train/100)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sSH-Hg2fZvKP"
      },
      "source": [
        "Accuracy on valid parenthesis strings only:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn4MCPRDgjV2"
      },
      "outputs": [],
      "source": [
        "correctsL_test, labelsL_test = test(lstm, lambda: generator.generate_input(len_r=seq_max_len,true_parent=True))\n",
        "np.sum(correctsL_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_GZSFHxZvKR"
      },
      "source": [
        "Accuracy on a test set (similar to the training set):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b06Gp7lrgjWC"
      },
      "outputs": [],
      "source": [
        "correctsL_test, labelsL_test = test(lstm, lambda: generator.generate_input(len_r=seq_max_len, hard_false = True))\n",
        "np.sum(correctsL_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tskqOH5vZvKV"
      },
      "source": [
        "Accuracy on a test set of hard instances, i.e. instances longer than those seen during the training :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zh43kUcGgjWI"
      },
      "outputs": [],
      "source": [
        "correctshL_test, labelshL_test = test(lstm, lambda: generator.generate_input_hard())\n",
        "np.sum(correctshL_test)/nb_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWUSVdiggjWO"
      },
      "source": [
        "## 5. GRU\n",
        "\n",
        "Implement your RNN with a [GRU](https://pytorch.org/docs/stable/nn.html#gru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSH65GakgjWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvHhG7KfgjWe"
      },
      "source": [
        "## 6. Explore!\n",
        "\n",
        "What are good negative examples?\n",
        "\n",
        "How to be sure that your network 'generalizes'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCVb66-xgjWj"
      },
      "source": [
        "[![Dataflowr](https://raw.githubusercontent.com/dataflowr/website/master/_assets/dataflowr_logo.png)](https://dataflowr.github.io/website/)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}